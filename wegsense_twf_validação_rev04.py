# -*- coding: utf-8 -*-
"""WEGsense TWF Validação rev04

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1SyOU7dWupSy50i4Bi50F6gGeCZfvk4HQ
"""

!pip install losant-rest
!pip install sounddevice
!sudo apt-get install portaudio19-dev
!pip install pydub
!pip install pandas
!pip install matplotlib
!pip install requests
!pip install nome_do_modulo
!conda install nome_do_modulo
!pip install numpy scipy

TOKEN_DEV = "eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJzdWIiOiI2MmMzNWE4NTM0ODcwNzBlM2IwMDAzZDAiLCJzdWJ0eXBlIjoiYXBpVG9rZW4iLCJzY29wZSI6WyJhbGwuQXBwbGljYXRpb24iXSwiaWF0IjoxNjU2OTY5ODYxLCJpc3MiOiJhcHAud25vbG9neS5pbyJ9.cLHE-GW1EKlaKpiprc_lfb2piK909_QglbXaOUGbWbI"
APPLICATION_ID_DEV = "63dbb09f7d47a51c843f90a1"
TOKEN_PRD = "eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJzdWIiOiI2MjgzZjM4MDk2NjBiMGNkZjY4MjJjMTQiLCJzdWJ0eXBlIjoiYXBpVG9rZW4iLCJzY29wZSI6WyJhbGwuQXBwbGljYXRpb24iXSwiaWF0IjoxNjUyODE0NzIwLCJpc3MiOiJhcHAud25vbG9neS5pbyJ9.t0CDFUKHevI1vI_TvPth018NxxjM8IpjHVlTkb_ouPo"
APPLICATION_ID_PRD = "5eed0126ec59a70008902b45"
GOOGLE_CREDENTIAL_DEV = "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"

environment = "PRD"

if environment == "PRD":
  TOKEN = TOKEN_PRD
  APPLICATION_ID = APPLICATION_ID_PRD
else:
  TOKEN = TOKEN_DEV
  APPLICATION_ID = APPLICATION_ID_DEV

# Initialize device and data parameters

ENVIRONMENT = "PRD"
START = 1693845121000
END = 1696609921000
DEVICE_ID = "64ecc6e384a8e6cb7d75eb0f"

# Initialize cloud environment parameters

TOKEN_DEV = 'eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJzdWIiOiI2MmMzNWE4NTM0ODcwNzBlM2IwMDAzZDAiLCJzdWJ0eXBlIjoiYXBpVG9rZW4iLCJzY29wZSI6WyJhbGwuQXBwbGljYXRpb24iXSwiaWF0IjoxNjU2OTY5ODYxLCJpc3MiOiJhcHAud25vbG9neS5pbyJ9.cLHE-GW1EKlaKpiprc_lfb2piK909_QglbXaOUGbWbI'
APPLICATION_ID_DEV = '5ef213f8caefb100074029ad'
TOKEN_PRD = 'eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJzdWIiOiI2MjgzZjM4MDk2NjBiMGNkZjY4MjJjMTQiLCJzdWJ0eXBlIjoiYXBpVG9rZW4iLCJzY29wZSI6WyJhbGwuQXBwbGljYXRpb24iXSwiaWF0IjoxNjUyODE0NzIwLCJpc3MiOiJhcHAud25vbG9neS5pbyJ9.t0CDFUKHevI1vI_TvPth018NxxjM8IpjHVlTkb_ouPo'
APPLICATION_ID_PRD = '5eed0126ec59a70008902b45'
if ENVIRONMENT == "PRD":
    TOKEN = TOKEN_PRD
    APPLICATION_ID = APPLICATION_ID_PRD
else:
    TOKEN = TOKEN_DEV
    APPLICATION_ID = APPLICATION_ID_DEV

# Get microphone data from cloud

from losantrest import Client


client = Client(
    auth_token=TOKEN,
    url="https://api.app.wnology.io"
)
query = {
    "aggregation": "NONE",
    "resolution": 0,
    "start": START,
    "end": END,
    "attributes": [
        "micWaveformX",
        "micWaveformODR",
        "micWaveformScale",
        "temperatureB"
    ],
    "deviceIds": [
        DEVICE_ID
    ]
}

result = client.data.time_series_query(
    applicationId=APPLICATION_ID,
    query=query)

from losantrest import Client

query = {
    "aggregation": "NONE",
    "resolution": 0,
    "start": START,
    "end": END,
    "attributes": [
        "micCinfigSignal",
        "micWaveformODR",
        "micWaveformRaw",
        "micWaveformX",
        "micWaveformScale"
    ],
    "deviceIds": [
        DEVICE_ID
    ]
}

losant_client = Client (
    auth_token = TOKEN,
    url = "https://api.app.wnology.io"
)

result = losant_client.data.time_series_query (
    applicationId = APPLICATION_ID,
    query = query)
result

# Preprocess microphone data

import json
from datetime import datetime
from urllib.request import urlopen
from datetime import datetime
import json
from datetime import datetime
from urllib.request import urlopen
import csv


sampled_attributes = {
       "vibWaveformX",
    "vibWaveformY",
    "vibWaveformZ",
    "micWaveformX",
    "micWaveformY",
    "micWaveformZ",
    "magWaveformX",
    "magWaveformY",
    "magWaveformZ",
    "fftX",
    "fftY",
    "fftZ",

}

sensors = dict()
for device_id, device_value in result['devices'].items():
    print(device_value['points'])
    for point in device_value['points']:
        timestamp = int(datetime.fromisoformat(
            point['time'][:-1]).timestamp()*1000)
        for attribute_key, attribute_value in point['data'].items():
            if attribute_key in sampled_attributes:
                if device_id not in sensors:
                    sensors[device_id] = dict()
                if timestamp not in sensors[device_id]:
                    sensors[device_id][timestamp] = dict()
                axis = 'x' if 'X' in attribute_key else 'y' if 'Y' in attribute_key else 'z'
                if axis not in sensors[device_id][timestamp]:
                    sensors[device_id][timestamp][axis] = dict()
                curve = 'waveform' if 'Waveform' in attribute_key else 'spectrum'
                # Download blob file
                f = urlopen(attribute_value)
                bulk_dict = json.load(f)
                f.close()
                if 'Waveform' in attribute_key:
                    sensors[device_id][timestamp][axis][curve] = bulk_dict
                elif 'fft' in attribute_key:
                    if curve not in sensors[device_id][timestamp][axis]:
                        sensors[device_id][timestamp][axis][curve] = dict()
                    sensors[device_id][timestamp][axis][curve]['x'] = [
                        float(d['f']) for d in bulk_dict]
                    sensors[device_id][timestamp][axis][curve]['y'] = [
                        float(d['a']) for d in bulk_dict]
                print("Downloaded file", attribute_value)
            elif 'ODR' in attribute_key:
                if device_id not in sensors:
                    sensors[device_id] = dict()
                if timestamp not in sensors[device_id]:
                    sensors[device_id][timestamp] = dict()
                sensors[device_id][timestamp]['odr'] = attribute_value
            elif 'Scale' in attribute_key:
                if device_id not in sensors:
                    sensors[device_id] = dict()
                if timestamp not in sensors[device_id]:
                    sensors[device_id][timestamp] = dict()
                sensors[device_id][timestamp]['scale'] = attribute_value

import numpy as np
import matplotlib.pyplot as plt
import math
from scipy.signal import butter, filtfilt, welch
from scipy.stats import kurtosis
from IPython.display import Audio, display

TEST_CONDITION_SPL = 94.0  # dB SPL
MICROFONE_SENSITIVITY = -38  # dBV
VOLTAGE_REFERENCE_LEVEL = 10 ** (MICROFONE_SENSITIVITY / 20)

def from_voltages_to_dbv(signal):
    return [20.0*math.log10(voltage/VOLTAGE_REFERENCE_LEVEL)+ TEST_CONDITION_SPL for voltage in signal]

def extract_signal_from_timestamp(timestamp):
    signal_odr = int(sensors[DEVICE_ID][timestamp]['odr'])
    signal_scale = sensors[DEVICE_ID][timestamp]['scale']
    signal_base12 = sensors[DEVICE_ID][timestamp]['x']['waveform']

    signal_voltage = [i*3.6/4096.0 for i in signal_base12]
    signal_dbv = from_voltages_to_dbv(signal_voltage)
    return signal_dbv, signal_odr


def (signal):
    return (signal)

timestamps_to_analyze = [0, -1]

for index in timestamps_to_analyze:
    timestamp = list(sensors[DEVICE_ID].keys())[index]
    signal_dbv, signal_odr = extract_signal_from_timestamp(timestamp):

def spectral_subtraction(signal, noise, alpha=1.0, beta=1.0):
   Sy = np.abs(fft(signal)) ** beta
    Sn = np.abs(fft(noise)) ** beta
    Sx = np.maximum(Sy - alpha * Sn, 0) ** (1 / beta)
    return Sx

def analyze_band(signal, lowcut, highcut, fs):
    b, a = butter(1, [lowcut / (fs / 2), highcut / (fs / 2)], btype='band')
    filtered_signal = filtfilt(b, a, signal)
    dbV_rms = rms(filtered_signal)
    dbV_peak = np.max(filtered_signal)
    crest_factor = dbV_peak / dbV_rms
    kurt = kurtosis(filtered_signal)
    return dbV_rms, dbV_peak, crest_factor, kurt

def rms(signal):
    return np.sqrt(np.mean(np.square(signal)))

def spectral_noise_reduction(signal):
    # Aplicando a Transformada Discreta de Fourier
    Af = np.fft.fft(signal)
    frequency_spectrum = np.abs(Af) / len(signal)
    phase_spectrum = np.angle(Af)

    # Subtração espectral
    Sy = np.power(frequency_spectrum, beta)
    Sn = np.power(noise_spectrum, beta)
    Sx = np.maximum(Sy - alpha * Sn, 0)

    # Suavização do vizinho mais próximo
def smooth_spectrum(spectral_data, xi=0.5):
   smoothed_data = np.copy(spectral_data)
    for i in range(1, len(spectral_data)):
        smoothed_data[i] = smoothed_data[i-1] + xi * (spectral_data[i] - smoothed_data[i-1])
    return smoothed_data

    # Reconstruindo o sinal
    Af_filtered = Sx_smoothed * np.exp(1j * phase_spectrum)
    filtered_signal = np.fft.ifft(Af_filtered)

    return filtered_signal.real

def calculate_signal_features(signal):
    # Duração do sinal
    l = len(filtered_signal)
 rms = np.sqrt(np.mean(signal**2))  # Root Mean Square
    energy = np.sum(signal**2)  # Energy
    variance = np.var(signal)  # Variance
    kurtosis_value = kurtosis(signal, fisher=True)  # Kurtosis
    skewness = np.mean((signal - np.mean(signal))**3) / variance**1.5  # Skewness

    freq, power_spec_density = welch(signal, window='hamming')  # Power Spectral Density
    median_freq = np.median(freq)
    signal_power = np.sum(power_spec_density)
    spectral_rms = np.sqrt(np.sum(power_spec_density**2) / np.max(freq))
    entropy = -np.sum(freq * power_spec_density * np.log2(freq * power_spec_density))
    psd_variance = np.var(power_spec_density)
    psd_kurtosis = kurtosis(power_spec_density, fisher=True)
    psd_skewness = np.mean((power_spec_density - np.mean(power_spec_density))**3) / psd_variance**1.5

    features = {
        'rms': rms, 'energy': energy, 'variance': variance, 'kurtosis': kurtosis_value, 'skewness': skewness,
        'median_freq': median_freq, 'signal_power': signal_power, 'spectral_rms': spectral_rms,
        'entropy': entropy, 'psd_variance': psd_variance, 'psd_kurtosis': psd_kurtosis, 'psd_skewness': psd_skewness
    }
    return features
    # Cálculo no domínio do tempo
    rms_value = np.sqrt(np.sum(np.square(filtered_signal)) / l)
    energy = np.sum(np.square(filtered_signal))
    variance = np.var(filtered_signal, ddof=1)
    kurtosis_value = np.mean(np.power((filtered_signal - np.mean(filtered_signal)) / np.std(filtered_signal), 4)) - 3
    skewness = np.mean(np.power((filtered_signal - np.mean(filtered_signal)) / np.std(filtered_signal), 3))

    # Cálculo no domínio espectral
    frequencies, psd = welch(filtered_signal, fs=signal_odr, window='hamming')
    median_frequency = np.median(frequencies)
    signal_power = np.sum(psd)
    psd_rms = np.sqrt(np.sum(np.square(psd)) / np.max(frequencies))
    psd_entropy = -np.sum(frequencies * psd * np.log2(frequencies * psd))
    psd_variance = np.var(psd, ddof=1)
    psd_kurtosis = np.mean(np.power((psd - np.mean(psd)) / np.std(psd), 4)) - 3
    psd_skewness = np.mean(np.power((psd - np.mean(psd)) / np.std(psd), 3))

    return rms_value, energy, variance, kurtosis_value, skewness, median_frequency, signal_power, psd_rms, psd_entropy, psd_variance, psd_kurtosis, psd_skewness

def calculate_r2(psd1, psd2):
    residual_variance = np.sum(np.square(psd1 - psd2))
    total_variance = np.var(psd1, ddof=1) + np.var(psd2, ddof=1)
    return 1 - residual_variance / total_variance

def r2_clustering(psd_functions, similarity_threshold):
    clusters = []
    for psd_function in psd_functions:
        psd_normalized = psd_function / np.sum(psd_function)
        new_cluster = True
        for cluster in clusters:
            r2 = calculate_r2(psd_normalized, cluster)
            if r2 < similarity_threshold:
                new_cluster = False
                break
        if new_cluster:
            clusters.append(psd_normalized)
    return clusters

import numpy as np
import matplotlib.pyplot as plt
import math
from scipy.signal import butter, filtfilt
from scipy.stats import kurtosis
from IPython.display import Audio, display
from scipy.signal import welch


TEST_CONDITION_SPL = 94.0  # dB SPL
MICROFONE_SENSITIVITY = -38  # dBV
VOLTAGE_REFERENCE_LEVEL = 10 ** (MICROFONE_SENSITIVITY / 20)

def from_voltages_to_dbv(signal):
    return [20.0*math.log10(voltage/VOLTAGE_REFERENCE_LEVEL)+ TEST_CONDITION_SPL for voltage in signal]

def extract_signal_from_timestamp(timestamp):
    signal_odr = int(sensors[DEVICE_ID][timestamp]['odr'])
    signal_scale = sensors[DEVICE_ID][timestamp]['scale']
    signal_base12 = sensors[DEVICE_ID][timestamp]['x']['waveform']

    signal_voltage = [i*3.6/4096.0 for i in signal_base12]
    signal_dbv = from_voltages_to_dbv(signal_voltage)
    return signal_dbv, signal_odr

def analyze_band(signal, lowcut, highcut, fs):
    b, a = butter(1, [lowcut/(fs/2), highcut/(fs/2)], btype='band')
    filtered_signal = filtfilt(b, a, signal)
    dbV_rms = rms(filtered_signal)
    dbV_peak = np.max(filtered_signal)
    crest_factor = dbV_peak / dbV_rms
    kurt = kurtosis(filtered_signal)
    return dbV_rms, dbV_peak, crest_factor, kurt

def rms(signal):
    return np.sqrt(np.mean(np.square(signal)))

timestamps_to_analyze = [0, -1]

for index in timestamps_to_analyze:
    timestamp = list(sensors[DEVICE_ID].keys())[index]
    signal_dbv, signal_odr = extract_signal_from_timestamp(timestamp)

def spectral_noise_reduction(signal, noise_spectrum, alpha, beta):
    # Aplicando a Transformada Discreta de Fourier
    Af = np.fft.fft(signal)
    frequency_spectrum = np.abs(Af) / len(signal)
    phase_spectrum = np.angle(Af)

    # Subtração espectral
    Sy = np.power(frequency_spectrum, beta)
    Sn = np.power(noise_spectrum, beta)
    Sx = np.maximum(Sy - alpha * Sn, 0)

    # Suavização do vizinho mais próximo
    for i in range(1, len(Sx)):
        Sx_smoothed = Sx[i-1] + xi * (Sx[i] - Sx[i-1])

    # Reconstruindo o sinal
    Af_filtered = Sx_smoothed * np.exp(1j * phase_spectrum)
    filtered_signal = np.fft.ifft(Af_filtered)

    return filtered_signal.real

    from scipy.signal import welch

def calculate_features(filtered_signal):
    # Duração do sinal
    l = len(filtered_signal)

    # Cálculo no domínio do tempo
    rms = np.sqrt(np.sum(np.square(filtered_signal)) / l)
    energy = np.sum(np.square(filtered_signal))
    variance = np.var(filtered_signal, ddof=1)
    kurtosis = np.mean(np.power((filtered_signal - np.mean(filtered_signal)) / np.std(filtered_signal), 4)) - 3
    skewness = np.mean(np.power((filtered_signal - np.mean(filtered_signal)) / np.std(filtered_signal), 3))

    # Cálculo no domínio espectral
    frequencies, psd = welch(filtered_signal, fs=signal_odr, window='hamming')
    median_frequency = np.median(frequencies)
    signal_power = np.sum(psd)
    psd_rms = np.sqrt(np.sum(np.square(psd)) / np.max(frequencies))
    psd_entropy = -np.sum(frequencies * psd * np.log2(frequencies * psd))
    psd_variance = np.var(psd, ddof=1)
    psd_kurtosis = np.mean(np.power((psd - np.mean(psd)) / np.std(psd), 4)) - 3
    psd_skewness = np.mean(np.power((psd - np.mean(psd)) / np.std(psd), 3))

    return rms, energy, variance, kurtosis, skewness, median_frequency, signal_power, psd_rms, psd_entropy, psd_variance, psd_kurtosis, psd_skewness
    def r2_clustering(psd_functions, similarity_threshold):
    clusters = []
    for psd_function in psd_functions:
        psd_normalized = psd_function / np.sum(psd_function)
        new_cluster = True
        for cluster in clusters:
            r2 = calculate_r2(psd_normalized, cluster)
            if r2 < similarity_threshold:
                new_cluster = False
                break
        if new_cluster:
            clusters.append(psd_normalized)
    return clusters
def r2_clustering(psd_functions, similarity_threshold):
    clusters = []
    for psd_function in psd_functions:
        psd_normalized = psd_function / np.sum(psd_function)
        new_cluster = True
        for cluster in clusters:
            r2 = calculate_r2(psd_normalized, cluster)
            if r2 < similarity_threshold:
                new_cluster = False
                break
        if new_cluster:
            clusters.append(psd_normalized)
    return clusters

def calculate_r2(psd1, psd2):
    # Indentação correta para o corpo da função
    residual_variance = np.sum(np.square(psd1 - psd2))
    total_variance = np.var(psd1, ddof=1) + np.var(psd2, ddof=1)
    return 1 - residual_variance / total_variance

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from scipy.fft import rfft, irfft
from scipy.signal import welch, hanning
from sklearn.cluster import KMeans
from sklearn.decomposition import PCA
import math

# Constantes
TEST_CONDITION_SPL = 94.0  # dB SPL
MICROPHONE_SENSITIVITY = -38  # dBV
VOLTAGE_REFERENCE_LEVEL = 10 ** (MICROPHONE_SENSITIVITY / 20)
EPSILON = 1e-10  # Valor pequeno para evitar log de zero
FREQUENCIA_AMOSTRAGEM = 95949.76  # Hz
alpha = 0.5
beta = 1.0
rpm = 980

# Funções de processamento de sinal
def from_voltages_to_dbv(signal):
    return [20.0 * math.log10(max(voltage, EPSILON) / VOLTAGE_REFERENCE_LEVEL) + MICROPHONE_SENSITIVITY + TEST_CONDITION_SPL for voltage in signal]

def rpm_to_frequency(rpm):
    return rpm / 60.0

def apply_dft(signal):
    return rfft(signal)

def filter_fundamental_band(signal_fft, fundamental_freq, bandwidth=5):
    freqs = np.fft.rfftfreq(len(signal_fft) * 2 - 1, d=1.0/FREQUENCIA_AMOSTRAGEM)
    band_mask = np.abs(freqs - fundamental_freq) < bandwidth
    filtered_signal_fft = np.zeros_like(signal_fft)
    filtered_signal_fft[band_mask] = signal_fft[band_mask]
    return filtered_signal_fft

def subtract_noise(signal_fft, noise_fft):
    signal_magnitude = np.abs(signal_fft)
    noise_magnitude = np.abs(noise_fft)
    subtracted_magnitude = np.power(np.maximum(np.power(signal_magnitude, beta) - alpha * np.power(noise_magnitude, beta), 0), 1/beta)
    signal_phase = np.angle(signal_fft)
    return subtracted_magnitude * np.exp(1j * signal_phase)

def smooth_spectrum(spectrum):
    return np.convolve(spectrum, np.ones(3)/3, mode='same')

def apply_inverse_dft(signal_fft):
    return irfft(signal_fft)

# Funções para cálculo de características
def calculate_time_domain_features(signal):
    mean_signal = np.mean(signal)
    rms = np.sqrt(np.sum(np.square(signal)) / len(signal))
    energy = np.sum(np.square(signal))
    variance = np.var(signal)
    kurtosis = np.sum(((signal - mean_signal) / variance) ** 4) - 3
    skewness = np.sum(((signal - mean_signal) / variance) ** 3)
    return rms, energy, variance, kurtosis, skewness

def calculate_spectral_features(signal, sampling_rate):
    f, Pxx = welch(signal, fs=sampling_rate, window=hanning(len(signal)), nperseg=len(signal))
    Pxx_normalized = Pxx / np.sum(Pxx)
    return f, Pxx_normalized

# Funções para o Algoritmo de Clustering R²-K¹
def normalize_psd(Pxx):
    sum_Pxx = np.sum(Pxx)
    return Pxx / sum_Pxx if sum_Pxx > 0 else Pxx

def calculate_r_squared(Pxx1, Pxx2):
    Pxx1_normalized = normalize_psd(Pxx1)
    Pxx2_normalized = normalize_psd(Pxx2)
    residual_variance = np.sum(np.square(Pxx1_normalized - Pxx2_normalized))
    total_variance = np.sum(np.square(Pxx1_normalized)) - (np.sum(Pxx1_normalized) ** 2 / len(Pxx1_normalized))
    return 1 - residual_variance / total_variance if total_variance > 0 else 0

def identify_clusters(psd_list, similarity_threshold):
    n = len(psd_list)
    clusters = []
    for i in range(n):
        for j in range(i + 1, n):
            r_squared = calculate_r_squared(psd_list[i], psd_list[j])
            if r_squared < similarity_threshold:
                clusters.append((i, j))
    return clusters

# Supondo que 'signals' seja uma lista de arrays representando os sinais
signals = [...] # Substitua por sua lista de sinais
features = []
for signal in signals:
    signal_dbv = from_voltages_to_dbv(signal)
    signal_fft = apply_dft(signal_dbv)

    # Cálculo de características
    time_features = calculate_time_domain_features(signal_dbv)
    freq, Pxx_normalized = calculate_spectral_features(signal_dbv, FREQUENCIA_AMOSTRAGEM)
    combined_features = time_features + (freq.tolist(), Pxx_normalized.tolist())
    features.append(combined_features)

# Estruturação do DataFrame
columns = ['RMS', 'Energy', 'Variance', 'Kurtosis', 'Skewness', 'Frequency', 'Normalized_PSD']
feature_df = pd.DataFrame(features, columns=columns)

# Clustering com KMeans
num_clusters = 3
kmeans = KMeans(n_clusters=num_clusters)
clusters = kmeans.fit_predict(feature_df.drop(['Frequency', 'Normalized_PSD'], axis=1))

# Adicionando a informação do cluster aos dados
feature_df['Cluster'] = clusters

# Análise dos centroides dos clusters e redução de dimensionalidade (PCA)
pca = PCA(n_components=2)
reduced_data = pca.fit_transform(feature_df.drop(['Frequency', 'Normalized_PSD', 'Cluster'], axis=1))
centroids = kmeans.cluster_centers_

# Preparando os dados para a plotagem em heatmap
plt.figure(figsize=(12, 6))
plt.imshow(feature_df.drop(['Cluster'], axis=1), cmap='viridis', aspect='auto')
plt.colorbar(label='Intensidade')
plt.title('Heatmap das Características dos Sinais')
plt.xlabel('Características')
plt.ylabel('Timestamps')
plt.xticks(range(len(columns)), columns, rotation=45)
plt.show()

# Exibindo os primeiros elementos do DataFrame
print(feature_df.head())

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.cluster import KMeans
from sklearn.decomposition import PCA
import math
from scipy.fft import rfft, irfft
from scipy.signal import welch
from numpy import hanning

# Constantes
TEST_CONDITION_SPL = 94.0  # dB SPL
MICROPHONE_SENSITIVITY = -38  # dBV
VOLTAGE_REFERENCE_LEVEL = 10 ** (MICROPHONE_SENSITIVITY / 20)
N_TIMESTAMPS = 15  # Número de timestamps
SIGNAL_LENGTH = 32  # Comprimento de cada sinal
EPSILON = 1e-10  # Valor pequeno para evitar log de zero
alpha = 0.5
beta = 1.0
rpm = 980

# Funções de processamento de sinal
def from_voltages_to_dbv(signal):
    return [20.0 * math.log10(max(voltage, EPSILON) / VOLTAGE_REFERENCE_LEVEL) + MICROPHONE_SENSITIVITY + TEST_CONDITION_SPL for voltage in signal]

def apply_dft(signal):
    return rfft(signal)

def filter_fundamental_band(signal_fft, fundamental_freq, bandwidth=5):
    freqs = np.fft.rfftfreq(len(signal_fft) * 2 - 1, d=1.0/FREQUENCIA_AMOSTRAGEM)
    band_mask = np.abs(freqs - fundamental_freq) < bandwidth
    filtered_signal_fft = np.zeros_like(signal_fft)
    filtered_signal_fft[band_mask] = signal_fft[band_mask]
    return filtered_signal_fft

def subtract_noise(signal_fft, noise_fft):
    signal_magnitude = np.abs(signal_fft)
    noise_magnitude = np.abs(noise_fft)
    subtracted_magnitude = np.power(np.maximum(np.power(signal_magnitude, beta) - alpha * np.power(noise_magnitude, beta), 0), 1/beta)
    signal_phase = np.angle(signal_fft)
    return subtracted_magnitude * np.exp(1j * signal_phase)

def smooth_spectrum(spectrum):
    return np.convolve(spectrum, np.ones(3)/3, mode='same')

def apply_inverse_dft(signal_fft):
    return irfft(signal_fft)

# Funções para cálculo de características
def calculate_time_domain_features(signal):
    l = len(signal)
    mean_signal = np.mean(signal)
    rms = np.sqrt(np.sum(np.square(signal)) / l)
    energy = np.sum(np.square(signal))
    variance = np.var(signal)
    kurtosis = np.sum(((signal - mean_signal) / variance) ** 4) - 3
    skewness = np.sum(((signal - mean_signal) / variance) ** 3)
    return rms, energy, variance, kurtosis, skewness

def calculate_spectral_features(signal, sampling_rate):
    f, Pxx = welch(signal, fs=sampling_rate, window='hanning', nperseg=len(signal))
    Pxx_normalized = Pxx / np.sum(Pxx)
    spectral_centroid = np.sum(f * Pxx_normalized)
    spectral_bandwidth = np.sqrt(np.sum((f - spectral_centroid) ** 2 * Pxx_normalized))
    return spectral_centroid, spectral_bandwidth

# Gerando sinais aleatórios
signals = np.random.rand(N_TIMESTAMPS, SIGNAL_LENGTH)

# Processamento de sinais e extração de características
features = []
for signal in signals:
    # Processamento de sinal
    signal_dbv = from_voltages_to_dbv(signal)
    signal_fft = apply_dft(signal_dbv)
    # Aplicação de outras funções de processamento conforme necessário

    # Cálculo de características
    time_features = calculate_time_domain_features(signal_dbv)
    spectral_features = calculate_spectral_features(signal, FREQUENCIA_AMOSTRAGEM)
    combined_features = time_features + spectral_features
    features.append(combined_features)

# Convertendo as características para um DataFrame
feature_df = pd.DataFrame(features, columns=['RMS', 'Energy', 'Variance', 'Kurtosis', 'Skewness', 'Spectral_Centroid', 'Spectral_Bandwidth'])

# Clustering com KMeans
num_clusters = 3
kmeans = KMeans(n_clusters=num_clusters)
clusters = kmeans.fit_predict(feature_df)

# Adicionando a informação do cluster aos dados
feature_df['Cluster'] = clusters

# Análise dos centroides dos clusters
centroids = kmeans.cluster_centers_

# Reduzindo a dimensionalidade para visualização (usando PCA)
pca = PCA(n_components=2)
reduced_data = pca.fit_transform(feature_df.iloc[:, :-1])  # Excluindo a coluna de cluster

# Preparando os dados para a plotagem
reduced_df = pd.DataFrame(reduced_data, columns=['PCA1', 'PCA2'])
reduced_df['Cluster'] = clusters

# Plotando os dados e os centroides
plt.figure(figsize=(10, 6))
plt.scatter(reduced_df['PCA1'], reduced_df['PCA2'], c=reduced_df['Cluster'], alpha=0.6, cmap='viridis')
plt.scatter(centroids[:, 0], centroids[:, 1], c='red', s=50, marker='x')  # Centroides
plt.title('Visualização dos Clusters com PCA')
plt.xlabel('PCA1')
plt.ylabel('PCA2')
plt.show()

# Mostrando os primeiros elementos do DataFrame
print(feature_df.head())

features = []
for signal in signals:
    # Processamento de sinal
    signal_dbv = from_voltages_to_dbv(signal)
    signal_fft = apply_dft(signal_dbv)
    # [Aplique outras funções de processamento conforme necessário]

    # Cálculo de características
    time_features = calculate_time_domain_features(signal_dbv)
    spectral_features = calculate_spectral_features(signal, FREQUENCIA_AMOSTRAGEM)
    combined_features = time_features + spectral_features
    features.append(combined_features)

# Convertendo as características para um DataFrame
feature_df = pd.DataFrame(features, columns=['RMS', 'Energy', 'Variance', 'Kurtosis', 'Skewness', 'Spectral_Centroid', 'Spectral_Bandwidth'])

# Clustering com KMeans
num_clusters = 3
kmeans = KMeans(n_clusters=num_clusters)
clusters = kmeans.fit_predict(feature_df)

# Adicionando a informação do cluster aos dados
feature_df['Cluster'] = clusters

# Análise dos centroides dos clusters
centroids = kmeans.cluster_centers_

# Reduzindo a dimensionalidade para visualização (usando PCA)
pca = PCA(n_components=2)
reduced_data = pca.fit_transform(feature_df.iloc[:, :-1])  # Excluindo a coluna de cluster

# Preparando os dados para a plotagem
reduced_df = pd.DataFrame(reduced_data, columns=['PCA1', 'PCA2'])
reduced_df['Cluster'] = clusters

# Plotando os dados e os centroides
plt.figure(figsize=(10, 6))
plt.scatter(reduced_df['PCA1'], reduced_df['PCA2'], c=reduced_df['Cluster'], alpha=0.6, cmap='viridis')
plt.scatter(centroids[:, 0], centroids[:, 1], c='red', s=50, marker='x')  # Centroides
plt.title('Visualização dos Clusters com PCA')
plt.xlabel('PCA1')
plt.ylabel('PCA2')
plt.show()

# Mostrando os primeiros elementos do DataFrame
print(feature_df.head())

import numpy as np
import math
from scipy.fft import rfft, irfft
from scipy.signal import welch
import numpy as np
import matplotlib.pyplot as plt
from sklearn.cluster import KMeans
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.decomposition import PCA
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.cluster import KMeans
from sklearn.decomposition import PCA
import math
from scipy.fft import rfft, irfft
from scipy.signal import welch, hanning
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.cluster import KMeans
from sklearn.decomposition import PCA
import math
from scipy.fft import rfft, irfft
from scipy.signal import welch, hanning
# Constantes
TEST_CONDITION_SPL = 94.0  # dB SPL
MICROPHONE_SENSITIVITY = -38  # dBV
VOLTAGE_REFERENCE_LEVEL = 10 ** (MICROPHONE_SENSITIVITY / 20)
N_TIMESTAMPS = 15  # Número de timestamps
SIGNAL_LENGTH = 32  # Comprimento de cada sinal
EPSILON = 1e-10  # Valor pequeno para evitar log de zero
FREQUENCIA_AMOSTRAGEM = 95949.76  # Hz
alpha = 0.5
beta = 1.0
rpm = 980

# Funções de processamento de sinal
def from_voltages_to_dbv(signal):
    return [20.0 * math.log10(max(voltage, EPSILON) / VOLTAGE_REFERENCE_LEVEL) + MICROPHONE_SENSITIVITY + TEST_CONDITION_SPL for voltage in signal]

def rpm_to_frequency(rpm):
    return rpm / 60.0

def apply_dft(signal):
    return rfft(signal)

def filter_fundamental_band(signal_fft, fundamental_freq, bandwidth=5):
    freqs = np.fft.rfftfreq(len(signal_fft) * 2 - 1, d=1.0/FREQUENCIA_AMOSTRAGEM)
    band_mask = np.abs(freqs - fundamental_freq) < bandwidth
    filtered_signal_fft = np.zeros_like(signal_fft)
    filtered_signal_fft[band_mask] = signal_fft[band_mask]
    return filtered_signal_fft

def subtract_noise(signal_fft, noise_fft):
    signal_magnitude = np.abs(signal_fft)
    noise_magnitude = np.abs(noise_fft)
    subtracted_magnitude = np.power(np.maximum(np.power(signal_magnitude, beta) - alpha * np.power(noise_magnitude, beta), 0), 1/beta)
    signal_phase = np.angle(signal_fft)
    return subtracted_magnitude * np.exp(1j * signal_phase)

def smooth_spectrum(spectrum):
    return np.convolve(spectrum, np.ones(3)/3, mode='same')

def apply_inverse_dft(signal_fft):
    return irfft(signal_fft)

# Funções para cálculo de características
def calculate_time_domain_features(signal):
    l = len(signal)
    mean_signal = np.mean(signal)
    rms = np.sqrt(np.sum(np.square(signal)) / l)
    energy = np.sum(np.square(signal))
    variance = np.var(signal)
    kurtosis = np.sum(((signal - mean_signal) / variance) ** 4) - 3
    skewness = np.sum(((signal - mean_signal) / variance) ** 3)
    return rms, energy, variance, kurtosis, skewness

def calculate_spectral_features(signal, sampling_rate):
    f, Pxx = welch(signal, fs=sampling_rate, window=hanning(len(signal)), nperseg=len(signal))
    Pxx_normalized = Pxx / np.sum(Pxx)
    return f, Pxx_normalized

# Funções para o Algoritmo de Clustering R²-K¹
def normalize_psd(Pxx):
    sum_Pxx = np.sum(Pxx)
    return Pxx / sum_Pxx if sum_Pxx > 0 else Pxx

def calculate_r_squared(Pxx1, Pxx2):
    Pxx1_normalized = normalize_psd(Pxx1)
    Pxx2_normalized = normalize_psd(Pxx2)
    residual_variance = np.sum(np.square(Pxx1_normalized - Pxx2_normalized))
    total_variance = np.sum(np.square(Pxx1_normalized)) - (np.sum(Pxx1_normalized) ** 2 / len(Pxx1_normalized))
    return 1 - residual_variance / total_variance if total_variance > 0 else 0

def identify_clusters(psd_list, similarity_threshold):
    n = len(psd_list)
    clusters = [10]
    for i in range(n):
        for j in range(i + 1, n):
            r_squared = calculate_r_squared(psd_list[i], psd_list[j])
            if r_squared < similarity_threshold:
                clusters.append((i, j))

 features = []
for signal in signals:
    # Processamento de sinal
    signal_dbv = from_voltages_to_dbv(signal)
    signal_fft = apply_dft(signal_dbv)
    # [Aplique outras funções de processamento conforme necessário]

    # Cálculo de características
    time_features = calculate_time_domain_features(signal_dbv)
    freq_features = calculate_spectral_features(signal, FREQUENCIA_AMOSTRAGEM)
    combined_features = time_features + freq_features
    features.append(combined_features)

# Convertendo as características para um DataFrame
feature_df = pd.DataFrame(features, columns=['RMS', 'Energy', 'Variance', 'Kurtosis', 'Skewness', 'Frequency', 'Normalized_PSD'])

# Clustering com KMeans
num_clusters = 3
kmeans = KMeans(n_clusters=num_clusters)
clusters = kmeans.fit_predict(feature_df)

# Adicionando a informação do cluster aos dados
feature_df['Cluster'] = clusters

# Análise dos centroides dos clusters
centroids = kmeans.cluster_centers_

# Reduzindo a dimensionalidade para visualização (usando PCA)
pca = PCA(n_components=2)
reduced_data = pca.fit_transform(feature_df.iloc[:, :-1])  # Excluindo a coluna de cluster

# Preparando os dados para a plotagem
reduced_df = pd.DataFrame(reduced_data, columns=['PCA1', 'PCA2'])
reduced_df['Cluster'] = clusters

# Plotando os dados e os centroides
plt.figure(figsize=(10, 6))
plt.scatter(reduced_df['PCA1'], reduced_df['PCA2'], c=reduced_df['Cluster'], alpha=0.6, cmap='viridis')
plt.scatter(centroids[:, 0], centroids[:, 1], c='red', s=50, marker='x')  # Centroides
plt.title('Visualização dos Clusters com PCA')
plt.xlabel('PCA1')
plt.ylabel('PCA2')
plt.show()

# Mostrando os primeiros elementos do DataFrame
print(feature_df.head())

"""# Plotting
    plt.figure(figsize=(26, 10))

    # Plot original signal in dBV
    plt.subplot(2, 1, 1)
    plt.plot(signal_frequency, signal_dbv)
    plt.xlabel('Frequency (Hz)')
    plt.ylabel('(dBV)')
    plt.title(f'Signal in dBV for Timestamp {timestamp}')

    # Plot the PSD using masked values
    plt.subplot(2, 1, 2)
    plt.semilogy(frequencies_masked, Pxx_masked)
    plt.xlabel('Frequency (Hz)')
    plt.ylabel('PSD (dB/Hz)')
    plt.title('Power Spectral Density (PSD)')

    plt.tight_layout()
    plt.show()

    # Compute dBV RMS of the filtered signal
    dbV_rms = rms(filtered_signal)

    # Compute dBV Peak of the filtered signal
    dbV_peak = np.max(filtered_signal)

    # Compute Crest Factor of the filtered signal
    crest_factor = dbV_peak / dbV_rms

    # Display results
    print(f"Timestamp: {timestamp}")
    print("dBV RMS (Filtered):", dbV_rms)
    print("dBV Peak (Filtered):", dbV_peak)
    print("Crest Factor (Filtered):", crest_factor)
    print("------------------------------")
"""

import numpy as np
import matplotlib.pyplot as plt
import math
from scipy.signal import butter, filtfilt, welch, hamming
from scipy.stats import kurtosis, skew

# Constantes
TEST_CONDITION_SPL = 94.0  # dB SPL
MICROFONE_SENSITIVITY = -38  # dBV
VOLTAGE_REFERENCE_LEVEL = 10 ** (MICROFONE_SENSITIVITY / 20)

# 1. Conversão de voltagens para dBV
def from_voltages_to_dbv(signal):
    return [20.0 * math.log10(voltage / VOLTAGE_REFERENCE_LEVEL) + TEST_CONDITION_SPL for voltage in signal]

# 2. Cálculo do RMS do sinal
def rms(signal):
    return np.sqrt(np.mean(np.square(signal)))

# 3. Aplicação de filtro passa-banda
def apply_bandpass_filter(signal, lowcut, highcut, fs, order=1):
    b, a = butter(order, [lowcut / (fs / 2), highcut / (fs / 2)], btype='band')
    return filtfilt(b, a, signal)

# 4. Aplicação da Transformada Discreta de Fourier (DFT)
def apply_dft(signal):
    A_f = np.fft.fft(signal)
    S_f = np.abs(A_f) / len(signal)
    omega_f = np.angle(A_f)
    return S_f, omega_f

# 5. Subtração espectral e suavização do espectro
def spectral_subtraction(S_y, S_n, alpha, beta):
    S_x = (np.maximum(S_y**beta - alpha * S_n**beta, 0))**(1/beta)
    return S_x

def nearest_neighbor_smoothing(S_x, xi):
    S_smooth_x = np.copy(S_x)
    for i in range(1, len(S_x)):
        S_smooth_x[i] = S_smooth_x[i-1] + xi * (S_x[i] - S_smooth_x[i-1])
    return S_smooth_x

# 6. Reconstrução do sinal filtrado
def reconstruct_signal(S_smooth_x, omega_y, n):
    A_hat_f = S_smooth_x * np.exp(1j * omega_y)
    return np.real(np.fft.ifft(A_hat_f))

# 7. Modelagem de ruído de rotação
def model_rotation_noise(signal_length, peak_frequencies, amplitude=0.1):
    noise = np.zeros(signal_length)
    for f in peak_frequencies:
        noise += amplitude * np.sin(2 * np.pi * f * np.arange(signal_length) / signal_length)
    return noise

# 8. Cálculo de características no domínio do tempo e do espectro
def calculate_time_domain_features(signal):
    rms_val = rms(signal)
    energy = np.sum(np.square(signal))
    variance = np.var(signal)
    kurt_val = kurtosis(signal, fisher=False)
    skewness = skew(signal)
    return rms_val, energy, variance, kurt_val, skewness

def calculate_spectral_domain_features(signal, fs):
    f, G_q = welch(signal, fs=fs, window=hamming(len(signal), sym=False), scaling='density')
    median_freq = np.median(f)
    power = np.sum(G_q)
    spectral_rms = rms(G_q)
    entropy = -np.sum(G_q * np.log2(G_q + np.finfo(float).eps))
    variance_spectral = np.var(G_q)
    kurt_spectral = kurtosis(G_q, fisher=False)
    skew_spectral = skew(G_q)
    return median_freq, power, spectral_rms, entropy, variance_spectral, kurt_spectral, skew_spectral

# 9. Normalização das PSDs
def normalize_psd(G_q):
    return G_q / np.sum(G_q)

# 10. Cálculo da entropia espectral e do coeficiente R^2
def calculate_R2(G_q_ref, G_q):
    SS_res = np.sum((G_q_ref - G_q) ** 2)
    SS_tot = np.sum((G_q_ref - np.mean(G_q_ref)) ** 2)
    return 1 - (SS_res / SS_tot)

# 11. Agrupamento de sinais com base na similaridade de suas PSDs
def cluster_signals(signals, threshold=0.8):
    # [Implementar lógica de agrupamento]

# 12. Plotagem da evolução dos clusters e da média da PSD de cada cluster
def plot_clusters(time_points, cluster_labels, clusters_psd_means):

  # Número de clusters
    num_clusters = len(np.unique(cluster_labels))

    # Criando um gráfico de linha para a evolução dos clusters ao longo do tempo
    plt.figure(figsize=(10, 6))

    # Plotando a evolução dos clusters
    for cluster in range(num_clusters):
        # Filtrando os pontos de tempo para este cluster
        cluster_times = [time_points[i] for i in range(len(time_points)) if cluster_labels[i] == cluster]

        # Plotando os pontos de tempo para este cluster
        plt.scatter(cluster_times, [cluster] * len(cluster_times), label=f'Cluster {cluster}')


   # Evolução dos Clusters
    plt.figure(figsize=(12, 6))
    plt.plot(time_points, cluster_labels, label='Clusters', marker='o')
    plt.xlabel('Tempo')
    plt.ylabel('Cluster ID')
    plt.title('Evolução dos Clusters ao Longo do Tempo')
    plt.legend()
    plt.grid(True)
    plt.show()

    # Gráfico de Tempo do Cluster
    plt.figure(figsize=(12, 6))
    for i, cluster_mean_psd in enumerate(clusters_psd_means):
        plt.plot(cluster_mean_psd, label=f'Cluster {i}')
    plt.xlabel('Frequência')
    plt.ylabel('PSD Média')
    plt.title('Gráfico de Tempo do Cluster')
    plt.legend()
    plt.grid(True)
    plt.show()



import numpy as np
import matplotlib.pyplot as plt
import math
from scipy.signal import butter, filtfilt, welch
import numpy as np
from scipy.signal import welch, hamming
from scipy.stats import kurtosis, skew
import numpy as np
import matplotlib.pyplot as plt
import numpy as np
import matplotlib.pyplot as plt
import math
from scipy.signal import butter, filtfilt, welch, hamming
from scipy.stats import kurtosis, skew


TEST_CONDITION_SPL = 94.0  # dB SPL
MICROFONE_SENSITIVITY = -38  # dBV
VOLTAGE_REFERENCE_LEVEL = 10 ** (MICROFONE_SENSITIVITY / 20)

def from_voltages_to_dbv(signal):
    return [20.0 * math.log10(voltage / VOLTAGE_REFERENCE_LEVEL) + TEST_CONDITION_SPL for voltage in signal]

def rms(signal):
    return np.sqrt(np.mean(np.square(signal)))

# Iterate through all timestamps
timestamps = list(sensors[DEVICE_ID].keys())
for timestamp in timestamps:

    signal_odr = int(sensors[DEVICE_ID][timestamp]['odr'])
    signal_scale = sensors[DEVICE_ID][timestamp]['scale']
    signal_base12 = sensors[DEVICE_ID][timestamp]['x']['waveform']

    signal_voltage = [i * 3.6 / 4096.0 for i in signal_base12]
    signal_dbv = from_voltages_to_dbv(signal_voltage)
    signal_frequency = np.linspace(10000, signal_odr / 2.56, len(signal_dbv))

    # Calculate PSD using Welch's method
    frequencies, Pxx = welch(signal_dbv, fs=signal_odr, nperseg=1024)

    # Mask the frequencies and Pxx for values >= 25,000 Hz
    mask = frequencies >= 10000
    frequencies_masked = frequencies[mask]
    Pxx_masked = Pxx[mask]

    # Design bandpass filter between 10 kHz and 38 kHz
    fs = signal_odr  # Sampling frequency
    lowcut = 10000  # Lower cut-off frequency (10 kHz)
    highcut = 38000  # Upper cut-off frequency (38 kHz)
    b, a = butter(1, [lowcut / (fs / 2), highcut / (fs / 2)], btype='band')

    # Apply the filter to the signal
    filtered_signal = filtfilt(b, a, signal_dbv)

def apply_dft(filtered_signal):
    """ Aplica a Transformada Discreta de Fourier no sinal. """
    A_f = np.fft.fft(filtered_signal)
    S_f = np.abs(A_f) / len(filtered_signal)
    omega_f = np.angle(A_f)
    return S_f, omega_f

def spectral_subtraction(S_y, S_n, alpha, beta):
    """ Realiza a subtração espectral. """
    S_x = (np.maximum(S_y**beta - alpha * S_n**beta, 0))**(1/beta)
    return S_x

def nearest_neighbor_smoothing(S_x, xi):
    """ Suaviza o espectro usando o método do vizinho mais próximo. """
    S_smooth_x = np.copy(S_x)
    for i in range(1, len(S_x)):
        S_smooth_x[i] = S_smooth_x[i-1] + xi * (S_x[i] - S_smooth_x[i-1])
    return S_smooth_x

def reconstruct_signal(S_smooth_x, omega_y, n):
    """ Reconstrói o sinal filtrado. """
    A_hat_f = S_smooth_x * np.exp(1j * omega_y)
    filtered_signal = np.fft.ifft(A_hat_f)
    return np.real(filtered_signal)

def model_rotation_noise(signal_length, peak_frequencies, amplitude=0.1):
    noise = np.zeros(signal_length)
    for f in peak_frequencies:
        noise += amplitude * np.sin(2 * np.pi * f * np.arange(signal_length) / signal_length)
    return noise

# Parâmetros para a filtragem
alpha = 0.5  # Ajuste para a subtração espectral
beta = 1.5   # Ajuste para a subtração espectral
xi = 0.7     # Fator de suavização

# Definir as frequências de pico do ruído de rotação
peak_frequencies = [16, 20]

# Modelar o ruído de rotação
rotation_noise = model_rotation_noise(len(filtered_signal), peak_frequencies)
S_n = np.abs(np.fft.fft(rotation_noise)) / len(filtered_signal)

# Aplicar as funções no filtered_signal
S_y, omega_y = apply_dft(filtered_signal)
S_x = spectral_subtraction(S_y, S_n, alpha, beta)
S_smooth_x = nearest_neighbor_smoothing(S_x, xi)
noise_filtered_signal = reconstruct_signal(S_smooth_x, omega_y, len(filtered_signal))

def calculate_time_domain_features(filtered_signal):
    l = len(filtered_signal)
    mean_signal = np.mean(filtered_signal)

    # Valor quadrático médio da raiz do sinal (RMS)
    rms = np.sqrt(np.sum(np.square(filtered_signal)) / l)

    # Energia do sinal
    energy = np.sum(np.square(filtered_signal))

    # Variação do sinal
    variance = np.sqrt(np.sum(np.square(filtered_signal - mean_signal)) / (l - 1))

    # Curtose do sinal
    kurt = kurtosis(filtered_signal, fisher=False)

    # Distorção do sinal
    skewness = skew(filtered_signal)

    return rms, energy, variance, kurt, skewness

def calculate_spectral_domain_features(filtered_signal, fs):
    # Calculando a PSD usando o método de Welch com a janela Hamming correta
    f, G_q = welch(filtered_signal, fs=fs, window=hamming(len(filtered_signal), sym=False), scaling='density')

    f_max = np.max(f)
    mean_G_q = np.mean(G_q)

    # Frequência mediana
    median_freq = np.median(G_q)

    # Potência do sinal
    power = np.sum(G_q)

    # Valor quadrático médio da raiz do espectro (RMS espectral)
    spectral_rms = np.sqrt(np.sum(np.square(G_q)) / f_max)

    # Entropia PSD
    entropy = -np.sum(f * G_q * np.log2(f * G_q))

    # Variação PSD
    variance_spectral = np.sqrt(np.sum(np.square(G_q - mean_G_q)) / (len(f) - 1))

    # Curtose PSD
    kurt_spectral = kurtosis(G_q, fisher=False)

    # Distorção do PSD
    skew_spectral = skew(G_q)

    return median_freq, power, spectral_rms, entropy, variance_spectral, kurt_spectral, skew_spectral

time_features = calculate_time_domain_features(noise_filtered_signal)
spectral_features = calculate_spectral_domain_features(noise_filtered_signal, fs)

#Normalizar as funções de densidade espectral de potência (PSD) para cada sinal

# Função para calcular a entropia espectral
def calculate_entropy(f, G_q):
    epsilon = 1e-10
    entropy = -np.sum((f * G_q + epsilon) * np.log2(f * G_q + epsilon))
    return entropy

# Função para calcular o coeficiente de determinação R^2
def calculate_R2(G_q_ref, G_q, f_max):
    SS_res = np.sum((G_q_ref[:f_max] - G_q[:f_max]) ** 2)
    SS_tot = np.sum((G_q_ref[:f_max] - np.mean(G_q_ref[:f_max])) ** 2)
    R2 = 1 - (SS_res / (SS_tot + epsilon))
    return R2

# Função para agrupar sinais com base na similaridade de suas PSDs
def cluster_signals_with_info(filtered_signal, threshold=0.8):
    clusters = []
    cluster_info = []

    for i, signal in enumerate(filtered_signal):
        G_q = calculate_psd(signal)
        f_max = np.argmax(G_q)

        if i == 0:
            # Inicialize o primeiro cluster com o primeiro sinal
            cluster = {'filtered_signal': [signal], 'mean_psd': G_q}
            clusters.append(cluster)
            cluster_info.append({'cluster_id': 0, 'start_time': 0, 'end_time': 0})
            continue

        for cluster in clusters:
            G_q_ref = cluster['mean_psd']
            R2 = calculate_R2(G_q_ref, G_q, f_max)
            if R2 >= threshold:
                cluster['filtered_signal'].append(signal)
                cluster['mean_psd'] = np.mean([G_q] + cluster['filtered_signal'], axis=0)
                break
        else:
            # Se o sinal não se encaixa em nenhum cluster existente, crie um novo cluster
            cluster = {'filtered_signal': [signal], 'mean_psd': G_q}
            clusters.append(cluster)
            cluster_info.append({'cluster_id': len(clusters) - 1, 'start_time': i, 'end_time': i})

        # Atualize o tempo de término do cluster
        cluster_info[len(clusters) - 1]['end_time'] = i

    return clusters, cluster_info

# Chame a função para obter clusters e informações sobre eles
clusters, cluster_info = cluster_signals_with_info(noise_filtered_signal, threshold=0.8)

# Crie um gráfico para mostrar a evolução dos clusters ao longo do tempo
time_points = np.arange(len(noise_filtered_signal))
cluster_labels = np.zeros(len(time_points), dtype=int)  # Inicialize rótulos de cluster

for info in cluster_info:
    start_time = info['start_time']
    end_time = info['end_time']
    cluster_id = info['cluster_id']
    cluster_labels[start_time:end_time + 1] = cluster_id

# Plot da evolução dos clusters
plt.figure(figsize=(12, 6))
plt.plot(time_points, cluster_labels, label='Clusters', marker='o')
plt.xlabel('Tempo')
plt.ylabel('Cluster ID')
plt.title('Evolução dos Clusters ao Longo do Tempo')
plt.legend()
plt.grid(True)

# gráfico de tempo do cluster para mostrar as mudanças no mecanismo de desgaste plotar a média da PSD de cada cluster ao longo do tempo
cluster_psd_means = [np.mean(cluster['mean_psd']) for cluster in clusters]

plt.figure(figsize=(12, 6))
for i, cluster_mean_psd in enumerate(cluster_psd_means):
    plt.plot(cluster_mean_psd, label=f'Cluster {i}')
plt.xlabel('Frequência')
plt.ylabel('PSD Média')
plt.title('Gráfico de Tempo do Cluster')
plt.legend()
plt.grid(True)

plt.show()

import numpy as np
import matplotlib.pyplot as plt
import math
from scipy.signal import butter, filtfilt, welch
import numpy as np
from scipy.signal import welch, hamming
from scipy.stats import kurtosis, skew
import numpy as np
import matplotlib.pyplot as plt
from scipy.signal.windows import hamming

TEST_CONDITION_SPL = 94.0  # dB SPL
MICROFONE_SENSITIVITY = -38  # dBV
VOLTAGE_REFERENCE_LEVEL = 10 ** (MICROFONE_SENSITIVITY / 20)

def from_voltages_to_dbv(signal):
    return [20.0 * math.log10(voltage / VOLTAGE_REFERENCE_LEVEL) + TEST_CONDITION_SPL for voltage in signal]

def rms(signal):
    return np.sqrt(np.mean(np.square(signal)))

# Iterate through all timestamps
timestamps = list(sensors[DEVICE_ID].keys())
for timestamp in timestamps:

    signal_odr = int(sensors[DEVICE_ID][timestamp]['odr'])
    signal_scale = sensors[DEVICE_ID][timestamp]['scale']
    signal_base12 = sensors[DEVICE_ID][timestamp]['x']['waveform']

    signal_voltage = [i * 3.6 / 4096.0 for i in signal_base12]
    signal_dbv = from_voltages_to_dbv(signal_voltage)
    signal_frequency = np.linspace(10000, signal_odr / 2.56, len(signal_dbv))

    # Calculate PSD using Welch's method
    frequencies, Pxx = welch(signal_dbv, fs=signal_odr, nperseg=1024)

    # Mask the frequencies and Pxx for values >= 25,000 Hz
    mask = frequencies >= 10000
    frequencies_masked = frequencies[mask]
    Pxx_masked = Pxx[mask]

    # Design bandpass filter between 10 kHz and 38 kHz
    fs = signal_odr  # Sampling frequency
    lowcut = 10000  # Lower cut-off frequency (10 kHz)
    highcut = 38000  # Upper cut-off frequency (38 kHz)
    b, a = butter(1, [lowcut / (fs / 2), highcut / (fs / 2)], btype='band')

    # Apply the filter to the signal
    filtered_signal = filtfilt(b, a, signal_dbv)

def apply_dft(filtered_signal):
    """ Aplica a Transformada Discreta de Fourier no sinal. """
    A_f = np.fft.fft(filtered_signal)
    S_f = np.abs(A_f) / len(filtered_signal)
    omega_f = np.angle(A_f)
    return S_f, omega_f

def spectral_subtraction(S_y, S_n, alpha, beta):
    """ Realiza a subtração espectral. """
    S_x = (np.maximum(S_y**beta - alpha * S_n**beta, 0))**(1/beta)
    return S_x

def nearest_neighbor_smoothing(S_x, xi):
    """ Suaviza o espectro usando o método do vizinho mais próximo. """
    S_smooth_x = np.copy(S_x)
    for i in range(1, len(S_x)):
        S_smooth_x[i] = S_smooth_x[i-1] + xi * (S_x[i] - S_smooth_x[i-1])
    return S_smooth_x

def reconstruct_signal(S_smooth_x, omega_y, n):
    """ Reconstrói o sinal filtrado. """
    A_hat_f = S_smooth_x * np.exp(1j * omega_y)
    filtered_signal = np.fft.ifft(A_hat_f)
    return np.real(filtered_signal)

def model_rotation_noise(signal_length, peak_frequencies, amplitude=0.1):
    noise = np.zeros(signal_length)
    for f in peak_frequencies:
        noise += amplitude * np.sin(2 * np.pi * f * np.arange(signal_length) / signal_length)
    return noise

# Parâmetros para a filtragem
alpha = 0.5  # Ajuste para a subtração espectral
beta = 1.5   # Ajuste para a subtração espectral
xi = 0.7     # Fator de suavização

# Definir as frequências de pico do ruído de rotação
peak_frequencies = [16, 20]

# Modelar o ruído de rotação
rotation_noise = model_rotation_noise(len(filtered_signal), peak_frequencies)
S_n = np.abs(np.fft.fft(rotation_noise)) / len(filtered_signal)

# Aplicar as funções no filtered_signal
S_y, omega_y = apply_dft(filtered_signal)
S_x = spectral_subtraction(S_y, S_n, alpha, beta)
S_smooth_x = nearest_neighbor_smoothing(S_x, xi)
noise_filtered_signal = reconstruct_signal(S_smooth_x, omega_y, len(filtered_signal))

def calculate_time_domain_features(filtered_signal):
    l = len(filtered_signal)
    mean_signal = np.mean(filtered_signal)

    # Valor quadrático médio da raiz do sinal (RMS)
    rms = np.sqrt(np.sum(np.square(filtered_signal)) / l)

    # Energia do sinal
    energy = np.sum(np.square(filtered_signal))

    # Variação do sinal
    variance = np.sqrt(np.sum(np.square(filtered_signal - mean_signal)) / (l - 1))

    # Curtose do sinal
    kurt = kurtosis(filtered_signal, fisher=False)

    # Distorção do sinal
    skewness = skew(filtered_signal)

    return rms, energy, variance, kurt, skewness

def calculate_spectral_domain_features(filtered_signal, fs):
    # Calculando a PSD usando o método de Welch com a janela Hamming correta
    f, G_q = welch(filtered_signal, fs=fs, window=hamming(len(filtered_signal), sym=False), scaling='density')

    f_max = np.max(f)
    mean_G_q = np.mean(G_q)

    # Frequência mediana
    median_freq = np.median(G_q)

    # Potência do sinal
    power = np.sum(G_q)

    # Valor quadrático médio da raiz do espectro (RMS espectral)
    spectral_rms = np.sqrt(np.sum(np.square(G_q)) / f_max)

    # Entropia PSD
    entropy = -np.sum(f * G_q * np.log2(f * G_q))

    # Variação PSD
    variance_spectral = np.sqrt(np.sum(np.square(G_q - mean_G_q)) / (len(f) - 1))

    # Curtose PSD
    kurt_spectral = kurtosis(G_q, fisher=False)

    # Distorção do PSD
    skew_spectral = skew(G_q)

    return median_freq, power, spectral_rms, entropy, variance_spectral, kurt_spectral, skew_spectral

time_features = calculate_time_domain_features(noise_filtered_signal)
spectral_features = calculate_spectral_domain_features(noise_filtered_signal, fs)

#Normalizar as funções de densidade espectral de potência (PSD) para cada sinal

def calculate_R2(G_q_ref, G_q, f_max):
    """ Calcula o coeficiente R2 para duas funções de PSD normalizadas. """
    G_q_normalized = G_q / np.sum(G_q)
    G_q_ref_normalized = G_q_ref / np.sum(G_q_ref)

    S_res = np.sum((G_q_normalized - G_q_ref_normalized) ** 2) / (f_max - 2)
    S_tot = np.sum(G_q_normalized ** 2) - (np.sum(G_q_normalized) ** 2) / (f_max - 1)

    R2 = 1 - (S_res / S_tot)
    return R2

def cluster_signals(filtered_signal, threshold):
    """ Agrupa sinais com base na similaridade de suas PSDs normalizadas. """
    clusters = []
    for i, filtered_signal in enumerate(filtered_signal):
        G_q, _ = welch(filtered_signal[:, 0])
        f_max = len(G_q)
        for cluster in clusters:
            G_q_ref = cluster['mean_psd']
            R2 = calculate_R2(G_q_ref, G_q, f_max)
            if R2 >= threshold:
                cluster['filtered_signal'].append(signal)
                cluster['mean_psd'] = np.mean([G_q] + cluster['filtered_signal'], axis=0)
                break
        else:
            clusters.append({'filtered_signal': [signal], 'mean_psd': G_q})
    return clusters

def cluster_signals_with_info(filtered_signal, threshold):
    clusters = []
    cluster_info = []  # Lista para armazenar informações sobre os clusters
    for i, signal in enumerate(filtered_signal):
      G_q, _ = welch(filtered_signal[:, 0])
      f_max = len(G_q)

    for cluster in clusters:
    G_q_ref = cluster['mean_psd']
    R2 = calculate_R2(G_q_ref, G_q, f_max)
    if R2 >= threshold:
        cluster['filtered_signal'].append(signal)  # Corrigido para adicionar o sinal atual
        cluster['mean_psd'] = np.mean([G_q] + cluster['filtered_signal'], axis=0)
        break

        else:
            clusters.append({'signals': [signal], 'mean_psd': G_q})
            cluster_info.append({'cluster_id': len(clusters) - 1, 'start_time': i, 'end_time': i})

    return clusters, cluster_info

# Chame a função para obter clusters e informações sobre eles
clusters, cluster_info = cluster_signals_with_info(noise_filtered_signal, threshold=0.8)

# Crie um gráfico para mostrar a evolução dos clusters ao longo do tempo
time_points = np.arange(len(noise_filtered_signal))
cluster_labels = np.zeros(len(time_points), dtype=int)  # Inicialize rótulos de cluster

for info in cluster_info:
    start_time = info['start_time']
    end_time = info['end_time']
    cluster_id = info['cluster_id']
    cluster_labels[start_time:end_time + 1] = cluster_id

# Plot da evolução dos clusters
plt.figure(figsize=(12, 6))
plt.plot(time_points, cluster_labels, label='Clusters', marker='o')
plt.xlabel('Tempo')
plt.ylabel('Cluster ID')
plt.title('Evolução dos Clusters ao Longo do Tempo')
plt.legend()
plt.grid(True)

# gráfico de tempo do cluster para mostrar as mudanças no mecanismo de desgaste plotar a média da PSD de cada cluster ao longo do tempo
cluster_psd_means = [np.mean(cluster['mean_psd']) for cluster in clusters]

plt.figure(figsize=(12, 6))
for i, cluster_mean_psd in enumerate(cluster_psd_means):
    plt.plot(cluster_mean_psd, label=f'Cluster {i}')
plt.xlabel('Frequência')
plt.ylabel('PSD Média')
plt.title('Gráfico de Tempo do Cluster')
plt.legend()
plt.grid(True)

plt.show()

import numpy as np
import math
from scipy.fft import rfft, irfft
from scipy.signal import welch
import numpy as np

# Constantes
TEST_CONDITION_SPL = 94.0  # dB SPL
MICROPHONE_SENSITIVITY = -38  # dBV
VOLTAGE_REFERENCE_LEVEL = 10 ** (MICROPHONE_SENSITIVITY / 20)
N_TIMESTAMPS = 15  # Número de timestamps
SIGNAL_LENGTH = 32  # Comprimento de cada sinal
EPSILON = 1e-10  # Valor pequeno para evitar log de zero
FREQUENCIA_AMOSTRAGEM = 95949.76  # Hz
alpha = 0.5
beta = 1.0
rpm = 980

# Funções de processamento de sinal
def from_voltages_to_dbv(signal):
    return [20.0 * math.log10(max(voltage, EPSILON) / VOLTAGE_REFERENCE_LEVEL) + MICROPHONE_SENSITIVITY + TEST_CONDITION_SPL for voltage in signal]

def rpm_to_frequency(rpm):
    return rpm / 60.0

def apply_dft(signal):
    return rfft(signal)

def filter_fundamental_band(signal_fft, fundamental_freq, bandwidth=5):
    freqs = np.fft.rfftfreq(len(signal_fft) * 2 - 1, d=1.0/FREQUENCIA_AMOSTRAGEM)
    band_mask = np.abs(freqs - fundamental_freq) < bandwidth
    filtered_signal_fft = np.zeros_like(signal_fft)
    filtered_signal_fft[band_mask] = signal_fft[band_mask]
    return filtered_signal_fft

def subtract_noise(signal_fft, noise_fft):
    signal_magnitude = np.abs(signal_fft)
    noise_magnitude = np.abs(noise_fft)
    subtracted_magnitude = np.power(np.maximum(np.power(signal_magnitude, beta) - alpha * np.power(noise_magnitude, beta), 0), 1/beta)
    signal_phase = np.angle(signal_fft)
    return subtracted_magnitude * np.exp(1j * signal_phase)

def smooth_spectrum(spectrum):
    return np.convolve(spectrum, np.ones(3)/3, mode='same')

def apply_inverse_dft(signal_fft):
    return irfft(signal_fft)

# Funções para cálculo de características
def calculate_time_domain_features(signal):
    l = len(signal)
    mean_signal = np.mean(signal)
    rms = np.sqrt(np.sum(np.square(signal)) / l)
    energy = np.sum(np.square(signal))
    variance = np.var(signal)
    kurtosis = np.sum(((signal - mean_signal) / variance) ** 4) - 3
    skewness = np.sum(((signal - mean_signal) / variance) ** 3)
    return rms, energy, variance, kurtosis, skewness

def calculate_spectral_features(signal, sampling_rate):
    f, Pxx = welch(signal, fs=sampling_rate, window=hanning(len(signal)), nperseg=len(signal))
    Pxx_normalized = Pxx / np.sum(Pxx)
    return f, Pxx_normalized

# Funções para o Algoritmo de Clustering R²-K¹
def normalize_psd(Pxx):
    sum_Pxx = np.sum(Pxx)
    return Pxx / sum_Pxx if sum_Pxx > 0 else Pxx

def calculate_r_squared(Pxx1, Pxx2):
    Pxx1_normalized = normalize_psd(Pxx1)
    Pxx2_normalized = normalize_psd(Pxx2)
    residual_variance = np.sum(np.square(Pxx1_normalized - Pxx2_normalized))
    total_variance = np.sum(np.square(Pxx1_normalized)) - (np.sum(Pxx1_normalized) ** 2 / len(Pxx1_normalized))
    return 1 - residual_variance / total_variance if total_variance > 0 else 0

def identify_clusters(psd_list, similarity_threshold):
    n = len(psd_list)
    clusters = []
    for i in range(n):
        for j in range(i + 1, n):
            r_squared = calculate_r_squared(psd_list[i], psd_list[j])
            if r_squared < similarity_threshold:
                clusters.append((i, j))
    return clusters

import numpy as np
import matplotlib.pyplot as plt
import math
from scipy.fft import rfft, irfft
from scipy.signal import welch
from numpy import hanning
import matplotlib.pyplot as plt
import numpy as np
from scipy.signal import welch

# Constantes
TEST_CONDITION_SPL = 94.0  # dB SPL
MICROPHONE_SENSITIVITY = -38  # dBV
VOLTAGE_REFERENCE_LEVEL = 10 ** (MICROPHONE_SENSITIVITY / 20)
N_TIMESTAMPS = 15  # Número de timestamps
SIGNAL_LENGTH = 32  # Comprimento de cada sinal
EPSILON = 1e-10  # Valor pequeno para evitar log de zero

def from_voltages_to_db(signal):
    return [20.0 * math.log10(max(voltage, EPSILON) / VOLTAGE_REFERENCE_LEVEL) + MICROPHONE_SENSITIVITY + TEST_CONDITION_SPL for voltage in signal]

# Get all timestamps (sua implementação)
timestamps = list(sensors[DEVICE_ID].keys())

# Iterate corresponding waveform
for timestamp in timestamps:
    signal_odr = int(sensors[DEVICE_ID][timestamp]['odr'])
    signal_scale = sensors[DEVICE_ID][timestamp]['scale']
    signal_base12 = sensors[DEVICE_ID][timestamp]['x']['waveform']

    # Convert signal to voltage
    signal_voltage = [i * 3.6 / 4096.0 for i in signal_base12]

    # Convert voltage to dB SPL
    signal_dbspl = from_voltages_to_db(signal_voltage)

    # Calculate time steps
    time = np.linspace(0, len(signal_dbspl) / signal_odr, len(signal_dbspl))

def apply_dft(signal_dbspl):
    return rfft(signal_dbspl)


def filter_fundamental_band(signal_fft, fundamental_freq, bandwidth=5):
    freqs = np.fft.rfftfreq(len(signal_fft) * 2 - 1, d=1.0/signal_odr)
    band_mask = np.abs(freqs - fundamental_freq) < bandwidth
    filtered_signal_fft = np.zeros_like(signal_fft)
    filtered_signal_fft[band_mask] = signal_fft[band_mask]
    return filtered_signal_fft

def subtract_noise(signal_fft, noise_fft):
    signal_magnitude = np.abs(signal_fft)
    noise_magnitude = np.abs(noise_fft)
    subtracted_magnitude = np.power(np.maximum(np.power(signal_magnitude, beta) - alpha * np.power(noise_magnitude, beta), 0), 1/beta)
    signal_phase = np.angle(signal_fft)
    return subtracted_magnitude * np.exp(1j * signal_phase)

def smooth_spectrum(spectrum):
    return np.convolve(spectrum, np.ones(3)/3, mode='same')

def apply_inverse_dft(signal_fft):
    return irfft(signal_fft)

def calculate_time_domain_features(signal_dbspl):
    l = len(signal_dbspl)
    mean_signal_dbspl = np.mean(signal_dbspl)
    rms = np.sqrt(np.sum(np.square(signal_dbspl)) / l)
    energy = np.sum(np.square(signal_dbspl))
    variance = np.var(signal_dbspl)
    kurtosis = np.sum(((signal_dbspl - mean_signal_dbspl) / variance) ** 4) - 3
    skewness = np.sum(((signal_dbspl - mean_signal_dbspl) / variance) ** 3)
    return rms, energy, variance, kurtosis, skewness

def calculate_spectral_features(signal_dbspl, sampling_rate):
    f, Pxx = welch(signal_dbspl, fs=sampling_rate, window=hanning(len(signal_dbspl)), nperseg=len(signal_dbspl))
    Pxx_normalized = Pxx / np.sum(Pxx)
    return f, Pxx_normalized



    return clusters
#Gráfico de Sinal no Tempo
plt.figure(figsize=(10, 4))
plt.plot(time, signal_dbspl)
plt.title('Sinal em dB SPL ao Longo do Tempo')
plt.xlabel('Tempo (s)')
plt.ylabel('dB SPL')
plt.grid(True)
plt.show()
#Espectro de Frequência
signal_fft = apply_dft(signal_dbspl)
freqs = np.fft.rfftfreq(len(signal_dbspl), d=1.0/signal_odr)

plt.figure(figsize=(10, 4))
plt.plot(freqs, np.abs(signal_fft))
plt.title('Espectro de Frequência do Sinal')
plt.xlabel('Frequência (Hz)')
plt.ylabel('Magnitude')
plt.grid(True)
plt.show()
#Densidade Espectral de Potência (PSD):
f, Pxx = calculate_spectral_features(signal_dbspl, signal_odr)

plt.figure(figsize=(10, 4))
plt.semilogy(f, Pxx)
plt.title('Densidade Espectral de Potência')
plt.xlabel('Frequência (Hz)')
plt.ylabel('PSD (dB/Hz)')
plt.grid(True)
plt.show()

#Histograma de Sinais:
plt.figure(figsize=(10, 4))
plt.hist(signal_dbspl, bins=20)
plt.title('Histograma do Sinal em dB SPL')
plt.xlabel('dB SPL')
plt.ylabel('Frequência')
plt.grid(True)
plt.show()

# Supondo que cada sinal tenha um atributo 'time' associado
for i, cluster in enumerate(clusters):
    plt.figure(figsize=(12, 6))
    for signal in cluster['signals']:
        plt.plot(signal.time, signal.data, label=f'Sinal {signal.id}')
    plt.title(f'Cluster {i + 1}')
    plt.xlabel('Tempo')
    plt.ylabel('Amplitude')
    plt.legend()
    plt.show()
# Escolha um cluster específico para plotar
cluster_index = 0  # Exemplo: primeiro cluster
selected_cluster = clusters[cluster_index]

plt.figure(figsize=(12, 6))
for signal in selected_cluster['signals']:
    plt.plot(signal.time, signal.data, label=f'Sinal {signal.id}')
plt.title(f'Cluster {cluster_index + 1}')
plt.xlabel('Tempo')
plt.ylabel('Amplitude')
plt.legend()
plt.show()



import numpy as np
import matplotlib.pyplot as plt
import math
from scipy.fft import rfft, irfft
from scipy.signal import welch
from numpy import hanning

# Constantes
TEST_CONDITION_SPL = 94.0  # dB SPL
MICROPHONE_SENSITIVITY = -38  # dBV
VOLTAGE_REFERENCE_LEVEL = 10 ** (MICROPHONE_SENSITIVITY / 20)
N_TIMESTAMPS = 15  # Número de timestamps
SIGNAL_LENGTH = 32  # Comprimento de cada sinal
EPSILON = 1e-10  # Valor pequeno para evitar log de zero

def from_voltages_to_db(signal):
    return [20.0 * math.log10(max(voltage, EPSILON) / VOLTAGE_REFERENCE_LEVEL) + MICROPHONE_SENSITIVITY + TEST_CONDITION_SPL for voltage in signal]

# Get all timestamps (sua implementação)
timestamps = list(sensors[DEVICE_ID].keys())

# Create a figure to plot the envelope
fig, ax = plt.subplots(figsize=(26, 10))

# Iterate over all timestamps corresponding waveform
for timestamp in timestamps:
    signal_odr = int(sensors[DEVICE_ID][timestamp]['odr'])
    signal_scale = sensors[DEVICE_ID][timestamp]['scale']
    signal_base12 = sensors[DEVICE_ID][timestamp]['x']['waveform']

    # Convert signal to voltage
    signal_voltage = [i * 3.6 / 4096.0 for i in signal_base12]

    # Convert voltage to dB SPL
    signal_dbspl = from_voltages_to_db(signal_voltage)

    # Calculate time steps
    time = np.linspace(0, len(signal_dbspl) / signal_odr, len(signal_dbspl))
    def apply_dft(signal_voltage):
    return rfft(signal_voltage)

def filter_fundamental_band(signal_fft, fundamental_freq, bandwidth=5):
    freqs = np.fft.rfftfreq(len(signal_fft) * 2 - 1, d=1.0/signal_odr)
    band_mask = np.abs(freqs - fundamental_freq) < bandwidth
    filtered_signal_fft = np.zeros_like(signal_fft)
    filtered_signal_fft[band_mask] = signal_fft[band_mask]
    return filtered_signal_fft

def subtract_noise(signal_fft, noise_fft):
    signal_magnitude = np.abs(signal_fft)
    noise_magnitude = np.abs(noise_fft)
    subtracted_magnitude = np.power(np.maximum(np.power(signal_magnitude, beta) - alpha * np.power(noise_magnitude, beta), 0), 1/beta)
    signal_phase = np.angle(signal_fft)
    return subtracted_magnitude * np.exp(1j * signal_phase)

def smooth_spectrum(spectrum):
    return np.convolve(spectrum, np.ones(3)/3, mode='same')

def apply_inverse_dft(signal_fft):
    return irfft(signal_fft)

def calculate_time_domain_features(signal_voltage):
    l = len(signal_voltage)
    mean_signal = np.mean(signal_voltage)
    rms = np.sqrt(np.sum(np.square(signal_voltage)) / l)
    energy = np.sum(np.square(signal_voltage))
    variance = np.var(signal_voltage)
    kurtosis = np.sum(((signal - mean_signal) / variance) ** 4) - 3
    skewness = np.sum(((signal - mean_signal) / variance) ** 3)
    return rms, energy, variance, kurtosis, skewness

def calculate_spectral_features(signal_voltage, sampling_rate):
    f, Pxx = welch(signal_voltage, fs=sampling_rate, window=hanning(len(signal_voltage)), nperseg=len(signal_voltage))
    Pxx_normalized = Pxx / np.sum(Pxx)
    return f, Pxx_normalized
def plot_time_domain_features(rms, energy, variance, kurtosis, skewness):
    features = [rms, energy, variance, kurtosis, skewness]
    labels = ['RMS', 'Energia', 'Variância', 'Curtose', 'Assimetria']

    plt.figure(figsize=(10, 6))
    plt.bar(labels, features)
    plt.title('Características no Domínio do Tempo')
    plt.show()

def plot_spectral_features(f, Pxx_normalized):
    plt.figure(figsize=(10, 6))
    plt.plot(f, Pxx_normalized)
    plt.title('Características Espectrais')
    plt.xlabel('Frequência (Hz)')
    plt.ylabel('Densidade Espectral de Potência Normalizada')
    plt.show()
# Calcular características no domínio do tempo
rms, energy, variance, kurtosis, skewness = calculate_time_domain_features(signal)
plot_time_domain_features(rms, energy, variance, kurtosis, skewness)

# Calcular características espectrais
f, Pxx_normalized = calculate_spectral_features(signal, signal_odr)
plot_spectral_features(f, Pxx_normalized)

"""O procedimento para filtragem de dados por subtração de ruído espectral – F1

"""

import numpy as np
import matplotlib.pyplot as plt
import math
from scipy.fft import rfft, irfft
from scipy.signal import welch
from numpy import hanning

# Constantes
TEST_CONDITION_SPL = 94.0  # dB SPL
MICROPHONE_SENSITIVITY = -38  # dBV
VOLTAGE_REFERENCE_LEVEL = 10 ** (MICROPHONE_SENSITIVITY / 20)
N_TIMESTAMPS = 15  # Número de timestamps
SIGNAL_LENGTH = 32  # Comprimento de cada sinal
EPSILON = 1e-10  # Valor pequeno para evitar log de zero
FREQUENCIA_AMOSTRAGEM = 95949.76  # Hz

# Reutilizando as funções definidas no código do usuário
def from_voltages_to_dbv(signal):
    return [20.0 * math.log10(max(voltage, EPSILON) / VOLTAGE_REFERENCE_LEVEL) + MICROPHONE_SENSITIVITY + TEST_CONDITION_SPL for voltage in signal]
def rpm_to_frequency(rpm):
    return rpm / 60.0

def apply_dft(signal):
    return rfft(signal)

def filter_fundamental_band(signal_fft, fundamental_freq, bandwidth=5):
    freqs = np.fft.rfftfreq(len(signal_fft) * 2 - 1, d=1.0/FREQUENCIA_AMOSTRAGEM)
    band_mask = np.abs(freqs - fundamental_freq) < bandwidth
    filtered_signal_fft = np.zeros_like(signal_fft)
    filtered_signal_fft[band_mask] = signal_fft[band_mask]
    return filtered_signal_fft

def subtract_noise(signal_fft, noise_fft):
    signal_magnitude = np.abs(signal_fft)
    noise_magnitude = np.abs(noise_fft)
    subtracted_magnitude = np.power(np.maximum(np.power(signal_magnitude, beta) - alpha * np.power(noise_magnitude, beta), 0), 1/beta)
    signal_phase = np.angle(signal_fft)
    return subtracted_magnitude * np.exp(1j * signal_phase)

def smooth_spectrum(spectrum):
    return np.convolve(spectrum, np.ones(3)/3, mode='same')

def apply_inverse_dft(signal_fft):
    return irfft(signal_fft)

def calculate_time_domain_features(signal):
    l = len(signal)
    mean_signal = np.mean(signal)
    rms = np.sqrt(np.sum(np.square(signal)) / l)
    energy = np.sum(np.square(signal))
    variance = np.var(signal)
    kurtosis = np.sum(((signal - mean_signal) / variance) ** 4) - 3
    skewness = np.sum(((signal - mean_signal) / variance) ** 3)
    return rms, energy, variance, kurtosis, skewness

def calculate_spectral_features(signal, sampling_rate):
    f, Pxx = welch(signal, fs=sampling_rate, window=hanning(len(signal)), nperseg=len(signal))
    Pxx_normalized = Pxx / np.sum(Pxx)
    return f, Pxx_normalized
def plot_time_domain_features(rms, energy, variance, kurtosis, skewness):
    features = [rms, energy, variance, kurtosis, skewness]
    labels = ['RMS', 'Energia', 'Variância', 'Curtose', 'Assimetria']

    plt.figure(figsize=(10, 6))
    plt.bar(labels, features)
    plt.title('Características no Domínio do Tempo')
    plt.show()

def plot_spectral_features(f, Pxx_normalized):
    plt.figure(figsize=(10, 6))
    plt.plot(f, Pxx_normalized)
    plt.title('Características Espectrais')
    plt.xlabel('Frequência (Hz)')
    plt.ylabel('Densidade Espectral de Potência Normalizada')
    plt.show()
# Calcular características no domínio do tempo
rms, energy, variance, kurtosis, skewness = calculate_time_domain_features(signal)
plot_time_domain_features(rms, energy, variance, kurtosis, skewness)

# Calcular características espectrais
f, Pxx_normalized = calculate_spectral_features(signal, FREQUENCIA_AMOSTRAGEM)
plot_spectral_features(f, Pxx_normalized)

import numpy as np
import math
from scipy.fft import rfft, irfft
from scipy.signal import welch
from numpy import hanning  # Importando hanning de numpy

# Constantes
TEST_CONDITION_SPL = 94.0  # dB SPL
MICROPHONE_SENSITIVITY = -38  # dBV
VOLTAGE_REFERENCE_LEVEL = 10 ** (MICROPHONE_SENSITIVITY / 20)
N_TIMESTAMPS = 15  # Número de timestamps
SIGNAL_LENGTH = 32  # Comprimento de cada sinal
EPSILON = 1e-10  # Valor pequeno para evitar log de zero
FREQUENCIA_AMOSTRAGEM = 95949.76  # Hz
alpha = 0.5
beta = 1.0

# Funções de processamento de sinal
def from_voltages_to_dbv(signal):
    return [20.0 * math.log10(max(voltage, EPSILON) / VOLTAGE_REFERENCE_LEVEL) + MICROPHONE_SENSITIVITY + TEST_CONDITION_SPL for voltage in signal]

def rpm_to_frequency(rpm):
    return rpm / 60.0

def apply_dft(signal):
    return rfft(signal)

def filter_fundamental_band(signal_fft, fundamental_freq, bandwidth=5):
    freqs = np.fft.rfftfreq(len(signal_fft) * 2 - 1, d=1.0/FREQUENCIA_AMOSTRAGEM)
    band_mask = np.abs(freqs - fundamental_freq) < bandwidth
    filtered_signal_fft = np.zeros_like(signal_fft)
    filtered_signal_fft[band_mask] = signal_fft[band_mask]
    return filtered_signal_fft

def subtract_noise(signal_fft, noise_fft):
    signal_magnitude = np.abs(signal_fft)
    noise_magnitude = np.abs(noise_fft)
    subtracted_magnitude = np.power(np.maximum(np.power(signal_magnitude, beta) - alpha * np.power(noise_magnitude, beta), 0), 1/beta)
    signal_phase = np.angle(signal_fft)
    return subtracted_magnitude * np.exp(1j * signal_phase)

def smooth_spectrum(spectrum):
    return np.convolve(spectrum, np.ones(3)/3, mode='same')

def apply_inverse_dft(signal_fft):
    return irfft(signal_fft)

# Funções para cálculo de características
def calculate_time_domain_features(signal):
    l = len(signal)
    mean_signal = np.mean(signal)
    rms = np.sqrt(np.sum(np.square(signal)) / l)
    energy = np.sum(np.square(signal))
    variance = np.var(signal)
    kurtosis = np.sum(((signal - mean_signal) / variance) ** 4) - 3
    skewness = np.sum(((signal - mean_signal) / variance) ** 3)
    return rms, energy, variance, kurtosis, skewness

def calculate_spectral_features(signal, sampling_rate):
    f, Pxx = welch(signal, fs=sampling_rate, window=hanning(len(signal)), nperseg=len(signal))
    Pxx_normalized = Pxx / np.sum(Pxx)
    return f, Pxx_normalized

# Funções para o Algoritmo de Clustering R²-K¹
def normalize_psd(Pxx):
    sum_Pxx = np.sum(Pxx)
    return Pxx / sum_Pxx if sum_Pxx > 0 else Pxx

def calculate_r_squared(Pxx1, Pxx2):
    Pxx1_normalized = normalize_psd(Pxx1)
    Pxx2_normalized = normalize_psd(Pxx2)
    residual_variance = np.sum(np.square(Pxx1_normalized - Pxx2_normalized))
    total_variance = np.sum(np.square(Pxx1_normalized)) - (np.sum(Pxx1_normalized) ** 2 / len(Pxx1_normalized))
    return 1 - residual_variance / total_variance if total_variance > 0 else 0

def identify_clusters(psd_list, similarity_threshold):
    n = len(psd_list)
    clusters = []
    for i in range(n):
        for j in range(i + 1, n):
            r_squared = calculate_r_squared(psd_list[i], psd_list[j])
            if r_squared < similarity_threshold:
                clusters.append((i, j))
    return clusters

# Exemplo de uso
# Converta a lista de sinais para um array do NumPy
signal = np.array(signals)
signal_dBv = from_voltages_to_dbv(signal)
signal_fft = apply_dft(signal_dBv)
filtered_signal_fft = filter_fundamental_band(signal_fft, rpm_to_frequency(380000))
time_features = calculate_time_domain_features(signal)

f, Pxx_normalized = calculate_spectral_features(signal, FREQUENCIA_AMOSTRAGEM)

# Suponha que você tenha uma lista de PSDs de diferentes sinais
psd_list = [Pxx_normalized, ...]  # Adicione outros PSDs normalizados aqui

similarity_threshold = 0.5  # Você pode ajustar este valor
clusters = identify_clusters(psd_list, similarity_threshold)

# Agora, 'clusters' contém os pares de índices dos sinais que foram agrupados

import numpy as np
import math
from scipy.fft import rfft, irfft
from scipy.signal import welch, hanning
import numpy as np

# Constantes
TEST_CONDITION_SPL = 94.0  # dB SPL
MICROPHONE_SENSITIVITY = -38  # dBV
VOLTAGE_REFERENCE_LEVEL = 10 ** (MICROPHONE_SENSITIVITY / 20)
N_TIMESTAMPS = 15  # Número de timestamps
SIGNAL_LENGTH = 32  # Comprimento de cada sinal
EPSILON = 1e-10  # Valor pequeno para evitar log de zero
FREQUENCIA_AMOSTRAGEM = 95949.76  # Hz
alpha = 0.5
beta = 1.0
rpm = 980

# Funções de processamento de sinal
def from_voltages_to_dbv(signal):
    return [20.0 * math.log10(max(voltage, EPSILON) / VOLTAGE_REFERENCE_LEVEL) + MICROPHONE_SENSITIVITY + TEST_CONDITION_SPL for voltage in signal]

def rpm_to_frequency(rpm):
    return rpm / 60.0

def apply_dft(signal):
    return rfft(signal)

def filter_fundamental_band(signal_fft, fundamental_freq, bandwidth=5):
    freqs = np.fft.rfftfreq(len(signal_fft) * 2 - 1, d=1.0/FREQUENCIA_AMOSTRAGEM)
    band_mask = np.abs(freqs - fundamental_freq) < bandwidth
    filtered_signal_fft = np.zeros_like(signal_fft)
    filtered_signal_fft[band_mask] = signal_fft[band_mask]
    return filtered_signal_fft

def subtract_noise(signal_fft, noise_fft):
    signal_magnitude = np.abs(signal_fft)
    noise_magnitude = np.abs(noise_fft)
    subtracted_magnitude = np.power(np.maximum(np.power(signal_magnitude, beta) - alpha * np.power(noise_magnitude, beta), 0), 1/beta)
    signal_phase = np.angle(signal_fft)
    return subtracted_magnitude * np.exp(1j * signal_phase)

def smooth_spectrum(spectrum):
    return np.convolve(spectrum, np.ones(3)/3, mode='same')

def apply_inverse_dft(signal_fft):
    return irfft(signal_fft)

# Funções para cálculo de características
def calculate_time_domain_features(signal):
    l = len(signal)
    mean_signal = np.mean(signal)
    rms = np.sqrt(np.sum(np.square(signal)) / l)
    energy = np.sum(np.square(signal))
    variance = np.var(signal)
    kurtosis = np.sum(((signal - mean_signal) / variance) ** 4) - 3
    skewness = np.sum(((signal - mean_signal) / variance) ** 3)
    return rms, energy, variance, kurtosis, skewness

def calculate_spectral_features(signal, sampling_rate):
    f, Pxx = welch(signal, fs=sampling_rate, window=hanning(len(signal)), nperseg=len(signal))
    Pxx_normalized = Pxx / np.sum(Pxx)
    return f, Pxx_normalized

# Funções para o Algoritmo de Clustering R²-K¹
def normalize_psd(Pxx):
    sum_Pxx = np.sum(Pxx)
    return Pxx / sum_Pxx if sum_Pxx > 0 else Pxx

def calculate_r_squared(Pxx1, Pxx2):
    Pxx1_normalized = normalize_psd(Pxx1)
    Pxx2_normalized = normalize_psd(Pxx2)
    residual_variance = np.sum(np.square(Pxx1_normalized - Pxx2_normalized))
    total_variance = np.sum(np.square(Pxx1_normalized)) - (np.sum(Pxx1_normalized) ** 2 / len(Pxx1_normalized))
    return 1 - residual_variance / total_variance if total_variance > 0 else 0

def identify_clusters(psd_list, similarity_threshold):
    n = len(psd_list)
    clusters = []
    for i in range(n):
        for j in range(i + 1, n):
            r_squared = calculate_r_squared(psd_list[i], psd_list[j])
            if r_squared < similarity_threshold:
                clusters.append((i, j))
    return clusters

# Exemplo de uso
# signal = [seu sinal aqui]  # Substitua com o seu sinal real
# signal_dBv = from_voltages_to_dbv(signal)
# signal_fft = apply_dft(signal_dBv)
# filtered_signal_fft = filter_fundamental_band(signal_fft, rpm_to_frequency(3000))
# time_features = calculate_time_domain_features(signal)
# f, Pxx_normalized = calculate_spectral_features(signal, FREQUENCIA_AMOSTRAGEM)

# psd_list = [Pxx_normalized de diferentes sinais]
# similarity_threshold = 0.5  # Defina seu critério de similaridade
# clusters = identify_clusters(psd_list, similarity_threshold)

import numpy as np
import matplotlib.pyplot as plt
from scipy.fft import rfft, irfft
import math
import json

TEST_CONDITION_SPL = 94.0  # dB SPL
MICROPHONE_SENSITIVITY = -38  # dBV
VOLTAGE_REFERENCE_LEVEL = 10 ** (MICROPHONE_SENSITIVITY / 20)
N_TIMESTAMPS = 15  # Número de timestamps
SIGNAL_LENGTH = 32  # Comprimento de cada sinal, ajustado para potência de 2
EPSILON = 1e-10  # Valor pequeno para evitar log de zero

# Frequência de amostragem média
FREQUENCIA_AMOSTRAGEM = 95949.76  # Hz

# Funções de processamento de sinal
def from_voltages_to_dbv(signal):
    return [20.0 * math.log10(max(voltage, EPSILON) / VOLTAGE_REFERENCE_LEVEL) + MICROPHONE_SENSITIVITY + TEST_CONDITION_SPL for voltage in signal]

def rpm_to_frequency(rpm):
    """Converte RPM (Rotações Por Minuto) para frequência em Hertz."""
    return rpm / 60.0

def apply_dft(signal):
    """Aplica a Transformada Rápida de Fourier (DFT) ao sinal."""
    return rfft(signal)

def filter_fundamental_band(signal_fft, fundamental_freq, bandwidth=5):
    """Filtra o sinal FFT para manter apenas frequências próximas à frequência fundamental."""
    # Atualizando o cálculo de freqs para combinar com o tamanho do signal_fft
    freqs = np.fft.rfftfreq(len(signal_fft) * 2 - 1, d=1.0/FREQUENCIA_AMOSTRAGEM)
    band_mask = np.abs(freqs - fundamental_freq) < bandwidth
    filtered_signal_fft = np.zeros_like(signal_fft)
    filtered_signal_fft[band_mask] = signal_fft[band_mask]
    return filtered_signal_fft


# Constantes para subtração de ruído
alpha = 0.5
beta = 1.0

def subtract_noise(signal_fft, noise_fft):
    """Subtrai ruído de um sinal FFT usando as constantes alpha e beta."""
    signal_magnitude = np.abs(signal_fft)
    noise_magnitude = np.abs(noise_fft)
    subtracted_magnitude = np.power(np.maximum(np.power(signal_magnitude, beta) - alpha * np.power(noise_magnitude, beta), 0), 1/beta)
    signal_phase = np.angle(signal_fft)
    return subtracted_magnitude * np.exp(1j * signal_phase)

def smooth_spectrum(spectrum):
    """Suaviza o espectro aplicando uma média móvel simples."""
    return np.convolve(spectrum, np.ones(3)/3, mode='same')

def apply_inverse_dft(signal_fft):
    """Aplica a Transformada Inversa de Fourier (IDFT) ao sinal FFT."""
    return irfft(signal_fft)



import numpy as np
import matplotlib.pyplot as plt
from scipy.fft import rfft, irfft
import math
import json

# Constantes
TEST_CONDITION_SPL = 94.0  # dB SPL
MICROPHONE_SENSITIVITY = -38  # dBV
VOLTAGE_REFERENCE_LEVEL = 10 ** (MICROPHONE_SENSITIVITY / 20)
N_TIMESTAMPS = 15  # Número de timestamps
SIGNAL_LENGTH = 32  # Comprimento de cada sinal, ajustado para potência de 2
EPSILON = 1e-10  # Valor pequeno para evitar log de zero

# Frequência de amostragem (exemplo, ajuste para o valor real)
FREQUENCIA_AMOSTRAGEM = 44100  # Hz

# Funções de processamento de sinal
def from_voltages_to_dbv(signal):
    return [20.0 * math.log10(max(voltage, EPSILON) / VOLTAGE_REFERENCE_LEVEL) + MICROPHONE_SENSITIVITY + TEST_CONDITION_SPL for voltage in signal]

def apply_dft(signal):
    return rfft(signal)
# Valores de alpha e beta
alpha = 0.5
beta = 1.0

def subtract_noise(signal_fft, noise_fft, alpha, beta):
    signal_magnitude = np.abs(signal_fft)
    noise_magnitude = np.abs(noise_fft)
    subtracted_magnitude = (np.maximum(signal_magnitude**beta - alpha * noise_magnitude**beta, 0))**(1/beta)
    signal_phase = np.angle(signal_fft)
    return subtracted_magnitude * np.exp(1j * signal_phase)

def smooth_spectrum(spectrum):
    smoothed = np.copy(spectrum)
    for i in range(1, len(spectrum) - 1):
        smoothed[i] = np.mean([spectrum[i-1], spectrum[i], spectrum[i+1]])
    return smoothed

def apply_inverse_dft(signal_fft):
    return irfft(signal_fft)

# Função para calcular RPM com base na frequência fundamental
def calculate_rpm(fundamental_frequency, frequencia_amostragem):
    return (fundamental_frequency * 60) / frequencia_amostragem

# Exemplo de uso
# Suponha que você tenha obtido o sinal de áudio em 'audio_signal'.
# Você precisa calcular a frequência fundamental do sinal e, em seguida, as RPM.
audio_signal = np.random.rand(SIGNAL_LENGTH)  # Exemplo de sinal (substitua com seus próprios dados)

# Aplicar o processamento de sinal (DFT, subtração de ruído, suavização, IDFT)
signal_fft = apply_dft(audio_signal)
noise_fft = apply_dft(noise_signal)  # Substitua 'noise_signal' pelo sinal de ruído real
filtered_signal_fft = subtract_noise(signal_fft, noise_fft, alpha, beta)
smoothed_spectrum = smooth_spectrum(np.abs(filtered_signal_fft))
filtered_signal = apply_inverse_dft(filtered_signal_fft)

# Calcular a frequência fundamental (substitua com seu próprio algoritmo de detecção)
fundamental_frequency = 1000.0  # Exemplo de frequência fundamental (substitua com a detecção real)

# Calcular RPM
rpm = calculate_rpm(fundamental_frequency, FREQUENCIA_AMOSTRAGEM)

# Imprimir o resultado
print("RPM calculado:", rpm)

import numpy as np
import matplotlib.pyplot as plt
from scipy.fft import rfft, irfft
import math
import json

# Constantes
TEST_CONDITION_SPL = 94.0  # dB SPL
MICROPHONE_SENSITIVITY = -38  # dBV
VOLTAGE_REFERENCE_LEVEL = 10 ** (MICROPHONE_SENSITIVITY / 20)
N_TIMESTAMPS = 15  # Número de timestamps
SIGNAL_LENGTH = 32  # Comprimento de cada sinal, ajustado para potência de 2
EPSILON = 1e-10  # Valor pequeno para evitar log de zero

# Funções de processamento de sinal
def from_voltages_to_dbv(signal):
    return [20.0 * math.log10(max(voltage, EPSILON) / VOLTAGE_REFERENCE_LEVEL) + MICROPHONE_SENSITIVITY + TEST_CONDITION_SPL for voltage in signal]

#  O procedimento para filtragem de dados por subtração de ruído espectral – F1

# Define uma função que aplica a Transformada Discreta de Fourier (DFT) a um sinal.
def apply_dft(signal):
    return rfft(signal)

# Valores de alpha e beta
alpha = 0.5
beta = 1.0

def subtract_noise(signal_fft, noise_fft, alpha, beta):
    signal_magnitude = np.abs(signal_fft)
    noise_magnitude = np.abs(noise_fft)
    subtracted_magnitude = (np.maximum(signal_magnitude**beta - alpha * noise_magnitude**beta, 0))**(1/beta)
    signal_phase = np.angle(signal_fft)
    return subtracted_magnitude * np.exp(1j * signal_phase)

def smooth_spectrum(spectrum):
    smoothed = np.copy(spectrum)
    for i in range(1, len(spectrum) - 1):
        smoothed[i] = np.mean([spectrum[i-1], spectrum[i], spectrum[i+1]])
    return smoothed

def apply_inverse_dft(signal_fft):
    return irfft(signal_fft)

import numpy as np
import matplotlib.pyplot as plt
from scipy.signal import welch, fftconvolve, hamming
from scipy.fft import rfft, irfft
from scipy.stats import kurtosis
import math

# Constantes
TEST_CONDITION_SPL = 94.0  # dB SPL
MICROPHONE_SENSITIVITY = -38  # dBV
VOLTAGE_REFERENCE_LEVEL = 10 ** (MICROPHONE_SENSITIVITY / 20)
N_TIMESTAMPS = 15  # Número de timestamps
SIGNAL_LENGTH = 20 # Comprimento de cada sinal
EPSILON = 1e-10  # Valor pequeno para evitar log de zero

# Funções de processamento de sinal
def from_voltages_to_dbv(signal):
    return [20.0 * math.log10(max(voltage, EPSILON) / VOLTAGE_REFERENCE_LEVEL) + MICROPHONE_SENSITIVITY + TEST_CONDITION_SPL for voltage in signal]

#  O procedimento para filtragem de dados por subtração de ruído espectral – F1

# Define uma função que aplica a Transformada Discreta de Fourier (DFT) a um sinal.
def apply_dft(signal):
    return rfft(signal)

#Define uma função que subtrai o ruído de um sinal no domínio da frequência.
def subtract_noise(signal_fft, noise_fft):
    return signal_fft - noise_fft

#Define uma função que suaviza um espectro de frequência.
def smooth_spectrum(spectrum):
    smoothed = np.copy(spectrum)
    for i in range(1, len(spectrum) - 1):
        smoothed[i] = np.mean([spectrum[i-1], spectrum[i], spectrum[i+1]])
    return smoothed

#Define uma função que aplica a Transformada Inversa Discreta de Fourier (IDFT) a um sinal no domínio da frequência.
def apply_inverse_dft(signal_fft, original_phase):
    magnitude = np.abs(signal_fft)
    return irfft(magnitude * np.exp(1j * original_phase))

# Funções para cálculo de parâmetros no domínio do tempo e da frequência
def calcular_rms(sinal):
    return np.sqrt(np.mean(sinal**2))

def calcular_energia(sinal):
    return np.sum(sinal**2)

def calcular_variacao(sinal):
    return np.var(sinal)

def calcular_curtose(sinal):
    return kurtosis(sinal)

def calcular_fator_de_crista(sinal):
    return np.max(np.abs(sinal)) / calcular_rms(sinal)

def calcular_distorcao(sinal):
    harmonicos = fftconvolve(sinal, sinal[::-1], mode='full')
    return np.max(harmonicos) / np.sum(harmonicos)

# Função para calcular PSD
def calcular_psd(sinal, fs):
    return welch(sinal, fs, window=hamming(len(sinal)), nperseg=len(sinal))

def calcular_frequencia_mediana(sinal, fs):
    freqs, psd = calcular_psd(sinal, fs)
    return freqs[np.argmax(psd)]

def calcular_potencia(sinal, fs):
    _, psd = calcular_psd(sinal, fs)
    return np.sum(psd)

def calcular_rms_espectro(sinal, fs):
    _, psd = calcular_psd(sinal, fs)
    return np.sqrt(np.mean(np.square(psd)))

def calcular_entropia_psd(sinal, fs):
    freqs, psd = calcular_psd(sinal, fs)
    psd_norm = psd / np.sum(psd)
    return -np.sum(psd_norm * np.log2(psd_norm + EPSILON))

def calcular_variacao_psd(sinal, fs):
    _, psd = calcular_psd(sinal, fs)
    return np.var(psd)

def calcular_curtose_psd(sinal, fs):
    _, psd = calcular_psd(sinal, fs)
    return kurtosis(psd)

def calcular_distorcao_psd(sinal, fs):
    _, psd = calcular_psd(sinal, fs)
    harmonicos = fftconvolve(psd, psd[::-1], mode='full')
    return np.max(harmonicos) / np.sum(harmonicos)


# Calculando e imprimindo os parâmetros no domínio do tempo
rms_sinal = calcular_rms(sinal)
energia_sinal = calcular_energia(sinal)
variacao_sinal = calcular_variacao(sinal)
curtose_sinal = calcular_curtose(sinal)
fator_de_crista_sinal = calcular_fator_de_crista(sinal)
distorcao_sinal = calcular_distorcao(sinal)

# Calculando e imprimindo os parâmetros no domínio da frequência
frequencia_mediana_sinal = calcular_frequencia_mediana(sinal, micWaveformODR)
potencia_sinal = calcular_potencia(sinal, micWaveformODR)
rms_espectro_sinal = calcular_rms_espectro(sinal, micWaveformODR)
entropia_psd_sinal = calcular_entropia_psd(sinal, micWaveformODR)
variacao_psd_sinal = calcular_variacao_psd(sinal, micWaveformODR)
curtose_psd_sinal = calcular_curtose_psd(sinal, micWaveformODR)
distorcao_psd_sinal = calcular_distorcao_psd(sinal, micWaveformODR)

# Plotando a PSD
freqs, psd = calcular_psd(sinal, micWaveformODR)
plt.plot(freqs, psd)
plt.xlabel("Frequência (Hz)")
plt.ylabel("PSD")
plt.title("Densidade do Espectro de Potência")
plt.show()

import numpy as np
import matplotlib.pyplot as plt
from scipy.fft import rfft, irfft
import math
from datetime import datetime

# Constantes
TEST_CONDITION_SPL = 94.0  # dB SPL
MICROPHONE_SENSITIVITY = -38  # dBV
VOLTAGE_REFERENCE_LEVEL = 10 ** (MICROPHONE_SENSITIVITY / 20)
EPSILON = 1e-10  # Valor pequeno para evitar log de zero

# Funções de processamento de sinal
def from_voltages_to_dbv(signal):
    return [20.0 * math.log10(max(voltage, EPSILON) / VOLTAGE_REFERENCE_LEVEL) + MICROPHONE_SENSITIVITY + TEST_CONDITION_SPL for voltage in signal]

def apply_dft(signal):
    return rfft(signal)

def subtract_noise(signal_fft, noise_fft, alpha, beta):
    signal_magnitude = np.abs(signal_fft)
    noise_magnitude = np.abs(noise_fft)
    subtracted_magnitude = (np.maximum(signal_magnitude**beta - alpha * noise_magnitude**beta, 0))**(1/beta)
    signal_phase = np.angle(signal_fft)
    return subtracted_magnitude * np.exp(1j * signal_phase)

def smooth_spectrum(spectrum):
    smoothed = np.copy(spectrum)
    for i in range(1, len(spectrum) - 1):
        smoothed[i] = np.mean([spectrum[i-1], spectrum[i], spectrum[i+1]])
    return smoothed

def apply_inverse_dft(signal_fft):
    return irfft(signal_fft)

# Dicionário sensors resultado da leitura do blob
sensors = {}  # Substitua com seus dados

# Atributos a serem amostrados
sampled_attributes = {"micWaveformX"}

# Populando o dicionário sensors com dados do result
result = {}  # Substitua com seus dados
for device_id, device_value in result['devices'].items():
    for point in device_value['points']:
        timestamp = int(datetime.fromisoformat(point['time'][:-1]).timestamp() * 1000)
        for attribute_key, attribute_value in point['data'].items():
            if attribute_key in sampled_attributes:
                if device_id not in sensors:
                    sensors[device_id] = dict()
                if timestamp not in sensors[device_id]:
                    sensors[device_id][timestamp] = dict()
                sensors[device_id][timestamp][attribute_key] = attribute_value

# Defina seu device_id e intervalo de timestamps
device_id = '64ed90d40423df79d8da0996'  # Exemplo de device_id
start_timestamp = 1693845121000  # Exemplo de timestamp inicial
end_timestamp = 1696609921000  # Exemplo de timestamp final

signals = []  # Inicialize a lista de sinais

# Verifica se o device_id está presente no dicionário sensors
if device_id in sensors:
    for timestamp, data in sensors[device_id].items():
        # Verifique se o timestamp está dentro do intervalo desejado
        if start_timestamp <= timestamp <= end_timestamp:
            # Extraia os dados do micWaveformX
            waveform_data = data['micWaveformX']
            # Adicione os dados à lista de sinais
            signals.append(waveform_data)

if not signals:
    print("Nenhum dado de sinal encontrado para o intervalo especificado.")
else:
    # Converta a lista de sinais para um array do NumPy
    signal = np.array(signals)

    # Processamento de sinal
    SIGNAL_LENGTH = len(signal)
    signal_fft = apply_dft(signal)
    noise_fft = apply_dft(np.zeros(SIGNAL_LENGTH))  # Exemplo de ruído nulo
    signal_filtered_fft = subtract_noise(signal_fft, noise_fft, alpha, beta)
    signal_filtered_fft_smooth = smooth_spectrum(signal_filtered_fft)
    signal_filtered = apply_inverse_dft(signal_filtered_fft_smooth)

    # Visualização
    plt.figure()
    plt.plot(signal, label='Original Signal')
    plt.plot(signal_filtered, label='Filtered Signal')
    plt.legend()
    plt.show()

import numpy as np
import matplotlib.pyplot as plt
from scipy.fft import rfft, irfft
import math
import json

# Constantes
TEST_CONDITION_SPL = 94.0  # dB SPL
MICROPHONE_SENSITIVITY = -38  # dBV
VOLTAGE_REFERENCE_LEVEL = 10 ** (MICROPHONE_SENSITIVITY / 20)
N_TIMESTAMPS = 15  # Número de timestamps
SIGNAL_LENGTH = 32  # Comprimento de cada sinal, ajustado para potência de 2
EPSILON = 1e-10  # Valor pequeno para evitar log de zero

# Funções de processamento de sinal
def from_voltages_to_dbv(signal):
    return [20.0 * math.log10(max(voltage, EPSILON) / VOLTAGE_REFERENCE_LEVEL) + MICROPHONE_SENSITIVITY + TEST_CONDITION_SPL for voltage in signal]

def apply_dft(signal):
    return rfft(signal)

def subtract_noise(signal_fft, noise_fft, alpha, beta):
    signal_magnitude = np.abs(signal_fft)
    noise_magnitude = np.abs(noise_fft)
    subtracted_magnitude = (np.maximum(signal_magnitude**beta - alpha * noise_magnitude**beta, 0))**(1/beta)
    signal_phase = np.angle(signal_fft)
    return subtracted_magnitude * np.exp(1j * signal_phase)

def smooth_spectrum(spectrum):
    smoothed = np.copy(spectrum)
    for i in range(1, len(spectrum) - 1):
        smoothed[i] = np.mean([spectrum[i-1], spectrum[i], spectrum[i+1]])
    return smoothed

def apply_inverse_dft(signal_fft):
    return irfft(signal_fft)

# Valores de alpha e beta
alpha = 0.5
beta = 1.0

# Dicionário sensors resultado da leitura do blob
sensors = {}  # Substitua com seus dados

# Defina seu device_id e intervalo de timestamps
device_id = '64ed90d40423df79d8da0996'
start_timestamp = '1693845121000'
end_timestamp = '1696609921000'

signals = []  # Inicialize a lista de sinais

# Verifica se o device_id está presente no dicionário sensors
if device_id in sensors:
    try:
        for timestamp, data in sensors[device_id].items():
            # Verifique se o timestamp está dentro do intervalo desejado
            if start_timestamp <= timestamp <= end_timestamp:
                # Extraia os dados do waveform para o eixo 'x'
                waveform_data = data['x']['micWaveform']
                # Adicione os dados à lista de sinais
                signals.append(waveform_data)
    except KeyError as e:
        print(f"Erro ao acessar os dados: {e}")
else:
    print(f"Device ID {device_id} não encontrado em sensors.")

if not signals:
    print("Nenhum dado de sinal encontrado para o intervalo especificado.")
else:
    # Converta a lista de sinais para um array do NumPy
    signal = np.array(signals)

    # Processamento de sinal
    SIGNAL_LENGTH = len(signal)
    signal_fft = apply_dft(signal)
    noise_fft = apply_dft(np.zeros(SIGNAL_LENGTH))  # Exemplo de ruído nulo
    signal_filtered_fft = subtract_noise(signal_fft, noise_fft, alpha, beta)
    signal_filtered_fft_smooth = smooth_spectrum(signal_filtered_fft)
    signal_filtered = apply_inverse_dft(signal_filtered_fft_smooth)

    # Visualização
    plt.figure()
    plt.plot(signal, label='Original Signal')
    plt.plot(signal_filtered, label='Filtered Signal')
    plt.legend()
    plt.show()

import numpy as np
import matplotlib.pyplot as plt
from scipy.signal import welch, fftconvolve, hamming
from scipy.fft import rfft, irfft
from scipy.stats import kurtosis
import math

# Constantes
TEST_CONDITION_SPL = 94.0  # dB SPL
MICROPHONE_SENSITIVITY = -38  # dBV
VOLTAGE_REFERENCE_LEVEL = 10 ** (MICROPHONE_SENSITIVITY / 20)
SIGNAL_LENGTH = 32  # Comprimento de cada sinal, ajustado para potência de 2
EPSILON = 1e-10  # Valor pequeno para evitar log de zero

# Funções de processamento de sinal
def from_voltages_to_dbv(signal):
    return [20.0 * math.log10(max(voltage, EPSILON) / VOLTAGE_REFERENCE_LEVEL) + MICROPHONE_SENSITIVITY + TEST_CONDITION_SPL for voltage in signal]

#  O procedimento para filtragem de dados por subtração de ruído espectral – F1

# Define uma função que aplica a Transformada Discreta de Fourier (DFT) a um sinal.
def apply_dft(signal):
    return rfft(signal)

#Define uma função que subtrai o ruído de um sinal no domínio da frequência.
def subtract_noise(signal_fft, noise_fft):
    return signal_fft - noise_fft

#Define uma função que suaviza um espectro de frequência.
def smooth_spectrum(spectrum):
    smoothed = np.copy(spectrum)
    for i in range(1, len(spectrum) - 1):
        smoothed[i] = np.mean([spectrum[i-1], spectrum[i], spectrum[i+1]])
    return smoothed

#Define uma função que aplica a Transformada Inversa Discreta de Fourier (IDFT) a um sinal no domínio da frequência.
def apply_inverse_dft(signal_fft, original_phase):
    magnitude = np.abs(signal_fft)
    return irfft(magnitude * np.exp(1j * original_phase))

# O procedimento para filtragem de dados por filtro FFT – F2
def aplicar_filtro_fft(sinal, ruído):
    dft_sinal = rfft(sinal)
    dft_ruído = rfft(ruído)
    C = calcular_coeficientes(dft_sinal, dft_ruído)
    Sx = dft_sinal * C
    return irfft(Sx)

def calcular_coeficientes(dft_sinal, dft_ruído):
    potencia_sinal = np.abs(dft_sinal)**2
    potencia_ruído = np.abs(dft_ruído)**2
    C = potencia_sinal / (potencia_sinal + potencia_ruído + EPSILON)
    return np.maximum(0, np.minimum(C, 1))

# Funções para cálculo de parâmetros no domínio do tempo e da frequência
def calcular_rms(sinal):
    return np.sqrt(np.mean(sinal**2))

def calcular_energia(sinal):
    return np.sum(sinal**2)

def calcular_variacao(sinal):
    return np.var(sinal)

def calcular_curtose(sinal):
    return kurtosis(sinal)

def calcular_fator_de_crista(sinal):
    return np.max(np.abs(sinal)) / calcular_rms(sinal)

def calcular_distorcao(sinal):
    harmonicos = fftconvolve(sinal, sinal[::-1], mode='full')
    return np.max(harmonicos) / np.sum(harmonicos)

# Função para calcular PSD
def calcular_psd(sinal, fs):
    return welch(sinal, fs, window=hamming(len(sinal)), nperseg=len(sinal))

def calcular_frequencia_mediana(sinal, fs):
    freqs, psd = calcular_psd(sinal, fs)
    return freqs[np.argmax(psd)]

def calcular_potencia(sinal, fs):
    _, psd = calcular_psd(sinal, fs)
    return np.sum(psd)

def calcular_rms_espectro(sinal, fs):
    _, psd = calcular_psd(sinal, fs)
    return np.sqrt(np.mean(np.square(psd)))

def calcular_entropia_psd(sinal, fs):
    freqs, psd = calcular_psd(sinal, fs)
    psd_norm = psd / np.sum(psd)
    return -np.sum(psd_norm * np.log2(psd_norm + EPSILON))

def calcular_variacao_psd(sinal, fs):
    _, psd = calcular_psd(sinal, fs)
    return np.var(psd)

def calcular_curtose_psd(sinal, fs):
    _, psd = calcular_psd(sinal, fs)
    return kurtosis(psd)

def calcular_distorcao_psd(sinal, fs):
    _, psd = calcular_psd(sinal, fs)
    harmonicos = fftconvolve(psd, psd[::-1], mode='full')
    return np.max(harmonicos) / np.sum(harmonicos)


# Calculando e imprimindo os parâmetros no domínio do tempo
rms_sinal = calcular_rms(sinal)
energia_sinal = calcular_energia(sinal)
variacao_sinal = calcular_variacao(sinal)
curtose_sinal = calcular_curtose(sinal)
fator_de_crista_sinal = calcular_fator_de_crista(sinal)
distorcao_sinal = calcular_distorcao(sinal)

# Calculando e imprimindo os parâmetros no domínio da frequência
frequencia_mediana_sinal = calcular_frequencia_mediana(sinal, micWaveformODR)
potencia_sinal = calcular_potencia(sinal, micWaveformODR)
rms_espectro_sinal = calcular_rms_espectro(sinal, micWaveformODR)
entropia_psd_sinal = calcular_entropia_psd(sinal, micWaveformODR)
variacao_psd_sinal = calcular_variacao_psd(sinal, micWaveformODR)
curtose_psd_sinal = calcular_curtose_psd(sinal, micWaveformODR)
distorcao_psd_sinal = calcular_distorcao_psd(sinal, micWaveformODR)

# Plotando a PSD
freqs, psd = calcular_psd(sinal, micWaveformODR)
plt.plot(freqs, psd)
plt.xlabel("Frequência (Hz)")
plt.ylabel("PSD")
plt.title("Densidade do Espectro de Potência")
plt.show()

import numpy as np
import matplotlib.pyplot as plt
import matplotlib.colors as mcolors
import math
from scipy.fft import fft, ifft
import scipy.stats as stats

# Constantes de configuração do microfone e nível de referência
TEST_CONDITION_SPL = 94.0  # dB SPL
MICROFONE_SENSITIVITY = -38  # dBV
VOLTAGE_REFERENCE_LEVEL = 10 ** (MICROFONE_SENSITIVITY / 20)
N_TIMESTAMPS = 15  # Número de timestamps
SIGNAL_LENGTH = 20 # Comprimento de cada sinal

# Função para converter voltagens em dBV
def from_voltages_to_dbv(signal):
    return [(20.0 * math.log10(abs(voltage) / VOLTAGE_REFERENCE_LEVEL) + MICROFONE_SENSITIVITY) + TEST_CONDITION_SPL for voltage in signal]

# Função para calcular a DFT de um sinal
def calculate_dft(signal):
    n = len(signal)
    dft_signal = fft(signal)
    amplitude_spectrum = np.abs(dft_signal) / n
    phase_spectrum = np.angle(dft_signal)
    return amplitude_spectrum, phase_spectrum

# Função para a subtração espectral de ruído
def noise_subtraction(original_spectrum, noise_spectrum, alpha=1.0, beta=2.0):
    filtered_spectrum = np.power(np.maximum(np.power(original_spectrum, beta) - alpha * np.power(noise_spectrum, beta), 0), 1/beta)
    return filtered_spectrum

# Função para suavização do vizinho mais próximo
def smooth_spectrum(spectrum, xi=0.5):
    smoothed_spectrum = np.copy(spectrum)
    for i in range(1, len(spectrum)):
        smoothed_spectrum[i] = smoothed_spectrum[i-1] + xi * (smoothed_spectrum[i] - smoothed_spectrum[i-1])
    return smoothed_spectrum

# Procedimento de filtragem F2 - Filtro FFT
def fft_filter_correction(original_spectrum, correction_function):
    return original_spectrum * correction_function

# Funções para calcular Fator de Crista e Curtose
def crest_factor(signal):
    rms_value = np.sqrt(np.mean(np.square(signal)))
    peak_value = np.max(np.abs(signal))
    return peak_value / rms_value if rms_value != 0 else 0

def kurtosis(signal):
    return stats.kurtosis(signal, fisher=False)

# Simulação de dados
np.random.seed(0)  # Para reprodutibilidade
sensors = {'DEVICE_ID': {'Timestamp {}'.format(i): {'odr': 96559.515625, 'scale': 2, 'x': {'waveform': np.random.randint(0, 4096, SIGNAL_LENGTH)}} for i in range(N_TIMESTAMPS)}}
DEVICE_ID = 'DEVICE_ID'

# Listas para armazenar os valores de Fator de Crista e Curtose
crest_factors = []
kurtosis_values = []

# Processamento de sinal para cada quadro de dados
timestamps = list(sensors[DEVICE_ID].keys())
for timestamp in timestamps:
    signal_data = sensors[DEVICE_ID][timestamp]
    signal_voltage = [i * 3.6 / 4096.0 for i in signal_data['x']['waveform']]
    signal_dbv = from_voltages_to_dbv(signal_voltage)

    # Aplicar DFT
    amplitude_spectrum, phase_spectrum = calculate_dft(signal_dbv)

    # Subtração espectral de ruído
    noise_spectrum = np.random.rand(len(amplitude_spectrum))  # Exemplo de espectro de ruído
    filtered_spectrum = noise_subtraction(amplitude_spectrum, noise_spectrum)

    # Suavização do espectro
    smoothed_spectrum = smooth_spectrum(filtered_spectrum)

    # Aplicação do filtro FFT
    correction_function = np.ones(len(smoothed_spectrum))  # Exemplo: Sem alteração
    corrected_spectrum = fft_filter_correction(smoothed_spectrum, correction_function)

    # Recuperação do sinal filtrado
    complex_amplitude = corrected_spectrum * np.exp(1j * phase_spectrum)
    filtered_signal = ifft(complex_amplitude).real  # Obtendo apenas a parte real

    # Cálculo do Fator de Crista e Curtose
    crest_factors.append(crest_factor(filtered_signal))
    kurtosis_values.append(kurtosis(filtered_signal))

# Convertendo listas em array para o heatmap
metrics_array = np.column_stack((crest_factors, kurtosis_values))

# Função para plotar heatmap
def plot_metrics_heatmap(data, labels, title="Heatmap de Métricas de Sinal"):
    plt.figure(figsize=(6, 10))
    plt.imshow(data, aspect='auto', cmap='RdYlGn', norm=mcolors.TwoSlopeNorm(vcenter=2))
    plt.colorbar(label='Intensidade')
    plt.title(title)
    plt.xlabel('Métricas')
    plt.ylabel('Timestamp')
    plt.xticks(range(len(labels)), labels)
    plt.show()

# Plotando o heatmap de Fator de Crista e Curtose
plot_metrics_heatmap(metrics_array, ['Fator de Crista', 'Curtose'])

import numpy as np
import matplotlib.pyplot as plt
import math
from scipy.fft import fft, ifft
from scipy.signal import welch, get_window
from scipy.stats import kurtosis

# Constantes de configuração do microfone e nível de referência
TEST_CONDITION_SPL = 94.0  # dB SPL
MICROFONE_SENSITIVITY = -38  # dBV
VOLTAGE_REFERENCE_LEVEL = 10 ** (MICROFONE_SENSITIVITY / 20)
N_TIMESTAMPS = 15  # Número de timestamps
SIGNAL_LENGTH = 20  # Comprimento de cada sinal

# Função para converter voltagens em dBV
def from_voltages_to_dbv(signal):
    return [(20.0 * math.log10(abs(voltage) / VOLTAGE_REFERENCE_LEVEL) + MICROFONE_SENSITIVITY) + TEST_CONDITION_SPL for voltage in signal]

# Função para calcular a DFT de um sinal
def calculate_dft(signal):
    n = len(signal)
    dft_signal = fft(signal)
    amplitude_spectrum = np.abs(dft_signal) / n
    phase_spectrum = np.angle(dft_signal)
    return amplitude_spectrum, phase_spectrum

# Função para a subtração espectral de ruído
def noise_subtraction(original_spectrum, noise_spectrum, alpha=1.0, beta=2.0):
    filtered_spectrum = np.power(np.maximum(np.power(original_spectrum, beta) - alpha * np.power(noise_spectrum, beta), 0), 1/beta)
    return filtered_spectrum

# Função para suavização do vizinho mais próximo
def smooth_spectrum(spectrum, xi=0.5):
    smoothed_spectrum = np.copy(spectrum)
    for i in range(1, len(spectrum)):
        smoothed_spectrum[i] = smoothed_spectrum[i-1] + xi * (smoothed_spectrum[i] - smoothed_spectrum[i-1])
    return smoothed_spectrum

# Procedimento de filtragem F2 - Filtro FFT
def fft_filter_correction(original_spectrum, correction_function):
    return original_spectrum * correction_function

# Funções adicionais para cálculo de características
def rms_value(signal):
    return np.sqrt(np.mean(np.square(signal)))

def signal_energy(signal):
    return np.sum(np.square(signal))

def signal_distortion(signal):
    return np.max(np.abs(signal)) / rms_value(signal)

def calculate_psd(signal, fs=1.0):
    f, psd = welch(signal, fs=fs, window='hamming', nperseg=len(signal)//2, noverlap=len(signal)//4)
    return f, psd

def median_frequency(psd, freqs):
    cumulative_sum = np.cumsum(psd)
    median_freq = freqs[np.searchsorted(cumulative_sum, cumulative_sum[-1] / 2)]
    return median_freq

def signal_power(psd):
    return np.sum(psd)

def psd_entropy(psd):
    normalized_psd = psd / np.sum(psd)
    return -np.sum(normalized_psd * np.log2(normalized_psd + 1e-10))

def psd_variance(psd):
    return np.var(psd)

def psd_kurtosis(psd):
    return kurtosis(psd)

def psd_distortion(psd):
    return np.max(psd) / rms_value(psd)

# Simulação de dados
np.random.seed(0)  # Para reprodutibilidade
sensors = {'DEVICE_ID': {'Timestamp {}'.format(i): {'odr': 96559.515625, 'scale': 2, 'x': {'waveform': np.random.randint(0, 4096, SIGNAL_LENGTH)}} for i in range(N_TIMESTAMPS)}}
DEVICE_ID = 'DEVICE_ID'

# Processamento de sinal para cada quadro de dados
timestamps = list(sensors[DEVICE_ID].keys())
for timestamp in timestamps:
    signal_data = sensors[DEVICE_ID][timestamp]
    signal_voltage = [i * 3.6 / 4096.0 for i in signal_data['x']['waveform']]
    signal_dbv = from_voltages_to_dbv(signal_voltage)

    amplitude_spectrum, phase_spectrum = calculate_dft(signal_dbv)

    noise_spectrum = np.random.rand(len(amplitude_spectrum))  # Exemplo de espectro de ruído
    filtered_spectrum = noise_subtraction(amplitude_spectrum, noise_spectrum)

    smoothed_spectrum = smooth_spectrum(filtered_spectrum)

    correction_function = np.ones(len(smoothed_spectrum))  # Exemplo: Sem alteração
    corrected_spectrum = fft_filter_correction(smoothed_spectrum, correction_function)

    complex_amplitude = corrected_spectrum * np.exp(1j * phase_spectrum)
    filtered_signal = ifft(complex_amplitude).real  # Obtendo apenas a parte real

    # Cálculo de características
    rms = rms_value(filtered_signal)
    energy = signal_energy(filtered_signal)
    variance = np.var(filtered_signal)
    kurt = kurtosis(filtered_signal)
    distortion = signal_distortion(filtered_signal)

    freqs, psd = calculate_psd(filtered_signal)
    median_freq = median_frequency(psd, freqs)
    power = signal_power(psd)
    rms_spectral = rms_value(psd)
    entropy = psd_entropy(psd)
    psd_var = psd_variance(psd)
    psd_kurt = psd_kurtosis(psd)
    psd_dist = psd_distortion(psd)

# Função para normalizar a PSD
def normalize_psd(psd):
    sum_psd = np.sum(psd)
    return psd / sum_psd if sum_psd != 0 else np.zeros_like(psd)

# Função para calcular o coeficiente de aproximação R^2
def calculate_r_squared(normalized_psd1, normalized_psd2):
    sr2 = np.sum((normalized_psd1 - normalized_psd2) ** 2) / (len(normalized_psd1) - 2)
    mean_psd = np.mean(normalized_psd1)
    st2 = np.sum(normalized_psd1 ** 2) - (len(normalized_psd1) * mean_psd ** 2) / (len(normalized_psd1) - 1)
    r_squared = 1 - sr2 / st2
    return r_squared

# Simulação de dados
np.random.seed(0)
sensors = {'DEVICE_ID': {'Timestamp {}'.format(i): {'odr': 96559.515625, 'scale': 2, 'x': {'waveform': np.random.randint(0, 4096, SIGNAL_LENGTH)}} for i in range(N_TIMESTAMPS)}}
DEVICE_ID = 'DEVICE_ID'

# Processamento de sinal para cada quadro de dados
normalized_psds = []  # Lista para armazenar as PSDs normalizadas
timestamps = list(sensors[DEVICE_ID].keys())
for timestamp in timestamps:
    signal_data = sensors[DEVICE_ID][timestamp]
    signal_voltage = [i * 3.6 / 4096.0 for i in signal_data['x']['waveform']]
    signal_dbv = from_voltages_to_dbv(signal_voltage)

    # [Processamento de sinal, DFT, subtração espectral, suavização, etc.]

    freqs, psd = calculate_psd(filtered_signal)
    normalized_psd = normalize_psd(psd)
    normalized_psds.append(normalized_psd)

    # [Cálculo de outras características e visualizações]

# Comparação de PSDs usando R^2
r_squared_values = []
for i in range(len(normalized_psds)):
    for j in range(i + 1, len(normalized_psds)):
        r_squared = calculate_r_squared(normalized_psds[i], normalized_psds[j])
        r_squared_values.append((timestamps[i], timestamps[j], r_squared))

# [Código para usar os valores de R^2 conforme necessário]
r_squared_results = []
for i in range(len(normalized_psds)):
    for j in range(i + 1, len(normalized_psds)):
        r_squared = calculate_r_squared(normalized_psds[i], normalized_psds[j])
        r_squared_results.append((timestamps[i], timestamps[j], r_squared))

# Preparação dos dados para plotagem
pairs = ["{} - {}".format(res[0], res[1]) for res in r_squared_results]
r_squared_values = [res[2] for res in r_squared_results]

# Plotagem dos valores de R^2
plt.figure(figsize=(30,20))
plt.bar(pairs, r_squared_values, color='skyblue')
plt.xlabel('Pares de Quadros de Tempo')
plt.ylabel('Coeficiente R^2')
plt.title('Comparação de Similaridade entre PSDs dos Quadros de Tempo')
plt.xticks(rotation=45, ha='right')
plt.tight_layout()
plt.show()

import numpy as np
import matplotlib.pyplot as plt
import matplotlib.colors as mcolors
import math
from scipy.stats import kurtosis

# Constantes de configuração do microfone e nível de referência
TEST_CONDITION_SPL = 94.0  # dB SPL
MICROFONE_SENSITIVITY = -38  # dBV
VOLTAGE_REFERENCE_LEVEL = 10 ** (MICROFONE_SENSITIVITY / 20)
N_TIMESTAMPS = 20 # Número de timestamps
SIGNAL_LENGTH = 30 # Comprimento de cada sinal
# Suponha que 'sensors' é o dicionário com os dados e 'DEVICE_ID' é o identificador do dispositivo

# Função para converter voltagens em dBV
def from_voltages_to_dbv(signal):
    return [(20.0 * math.log10(abs(voltage) / VOLTAGE_REFERENCE_LEVEL) + MICROFONE_SENSITIVITY) + TEST_CONDITION_SPL for voltage in signal]

# Função para calcular o valor RMS
def rms_value(signal):
    return np.sqrt(np.mean(np.square(signal)))

# Simulação de dados
np.random.seed(0)  # Para reprodutibilidade
sensors = {'DEVICE_ID': {'Timestamp {}'.format(i): {'odr': 96559.515625, 'scale': 2, 'x': {'waveform': np.random.randint(0, 4096, SIGNAL_LENGTH)}} for i in range(N_TIMESTAMPS)}}
DEVICE_ID = 'DEVICE_ID'

timestamps = list(sensors[DEVICE_ID].keys())

# Preparar dados para heatmaps
dbv_rms = []
dbv_peak = []
crest_factors = []
kurtosis_values = []
fator_de_defeito = []

for timestamp in timestamps:
    signal_data = sensors[DEVICE_ID][timestamp]
    signal_voltage = [i * 3.6 / 4096.0 for i in signal_data['x']['waveform']]
    signal_dbv = from_voltages_to_dbv(signal_voltage)
    dbv_rms.append(rms_value(signal_dbv))
    dbv_peak.append(max(signal_dbv))
    crest_factors.append(max(signal_dbv) / rms_value(signal_dbv))
    kurtosis_values.append(kurtosis(signal_dbv))

# Definir o colormap personalizado
colors = [(0, 1, 0), (1, 1, 0), (1, 0, 0)]  # Verde -> Amarelo -> Vermelho
n_bins = [20]  # Número de bins para cada cor
cmap_name = 'my_list'
cm = mcolors.LinearSegmentedColormap.from_list(cmap_name, colors, N=sum(n_bins))

# Aumentar o tamanho dos gráficos
fig, axs = plt.subplots(2, 2, figsize=(18, 16))  # Tamanho aumentado para 18x16 polegadas

# Heatmap para dBV RMS
rms_heatmap = np.array(dbv_rms).reshape(1, -1)
im = axs[0, 0].imshow(rms_heatmap, cmap=cm, interpolation='nearest', aspect='auto')
axs[0, 0].set_title('dBV RMS')
axs[0, 0].set_xticks(range(len(timestamps)))
axs[0, 0].set_xticklabels(timestamps, rotation=45, ha='right')
fig.colorbar(im, ax=axs[0, 0])  # Adiciona barra de cores ao gráfico

# Heatmap para dBV Peak
peak_heatmap = np.array(dbv_peak).reshape(1, -1)
im = axs[0, 1].imshow(peak_heatmap, cmap=cm, interpolation='nearest', aspect='auto')
axs[0, 1].set_title('dBV Peak')
axs[0, 1].set_xticks(range(len(timestamps)))
axs[0, 1].set_xticklabels(timestamps, rotation=45, ha='right')
fig.colorbar(im, ax=axs[0, 1])

# Heatmap para Crest Factor
crest_factor_heatmap = np.array(crest_factors).reshape(1, -1)
im = axs[1, 0].imshow(crest_factor_heatmap, cmap=cm, interpolation='nearest', aspect='auto')
axs[1, 0].set_title('Crest Factor')
axs[1, 0].set_xticks(range(len(timestamps)))
axs[1, 0].set_xticklabels(timestamps, rotation=45, ha='right')
fig.colorbar(im, ax=axs[1, 0])

# Heatmap para Kurtosis
kurtosis_heatmap = np.array(kurtosis_values).reshape(1, -1)
im = axs[1, 1].imshow(kurtosis_heatmap, cmap=cm, interpolation='nearest', aspect='auto')
axs[1, 1].set_title('Kurtosis')
axs[1, 1].set_xticks(range(len(timestamps)))
axs[1, 1].set_xticklabels(timestamps, rotation=45, ha='right')
fig.colorbar(im, ax=axs[1, 1])

# Ajustar layout e exibir o gráfico
plt.tight_layout()
plt.show()

import numpy as np
import matplotlib.pyplot as plt
import matplotlib.colors as mcolors
import math
import datetime
from scipy.stats import kurtosis
from scipy.signal import butter, filtfilt, hilbert

# Constantes de configuração do microfone e nível de referência
TEST_CONDITION_SPL = 94.0  # dB SPL
MICROFONE_SENSITIVITY = -38  # dBV
VOLTAGE_REFERENCE_LEVEL = 10 ** (MICROFONE_SENSITIVITY / 20)
N_TIMESTAMPS = 30  # Número de timestamps
SIGNAL_LENGTH = 120  # Comprimento de cada sinal

# Função para converter voltagens em dBV
def from_voltages_to_dbv(signal):
    return [(20.0 * math.log10(abs(voltage) / VOLTAGE_REFERENCE_LEVEL) + MICROFONE_SENSITIVITY) + TEST_CONDITION_SPL for voltage in signal]

# Função para calcular o valor RMS
def rms_value(signal):
    return np.sqrt(np.mean(np.square(signal)))

# Função para aplicar filtro passa-banda
def bandpass_filter(data, lowcut, highcut, fs, order=5):
    nyq = 0.5 * fs
    low = lowcut / nyq
    high = highcut / nyq
    b, a = butter(order, [low, high], btype='band')
    y = filtfilt(b, a, data)
    return y

# Função para extrair o envelope do sinal
def extract_envelope(signal):
    analytic_signal = hilbert(signal)
    envelope = np.abs(analytic_signal)
    return envelope

# Simulação de dados com timestamps convertidos para datas
base_time = datetime.datetime(2023, 1, 1)  # Data base (início da época Unix)
sensors = {'DEVICE_ID': {'Timestamp {}'.format((base_time + datetime.timedelta(milliseconds=i)).strftime('%Y-%m-%d %H:%M:%S.%f')): {'odr': 25600, 'scale': 2, 'x': {'waveform': np.random.randint(0, 4096, SIGNAL_LENGTH)}} for i in range(N_TIMESTAMPS)}}
DEVICE_ID = 'DEVICE_ID'

# Extração dos timestamps originais e conversão para formato legível
original_timestamps = [timestamp for timestamp in sensors[DEVICE_ID].keys()]
formatted_timestamps = [datetime.datetime.strptime(timestamp.replace('Timestamp ', ''), '%Y-%m-%d %H:%M:%S.%f').strftime('%Y-%m-%d %H:%M:%S') for timestamp in original_timestamps]

# Preparar dados para heatmaps
dbv_rms = []
dbv_peak = []
crest_factors = []
kurtosis_values = []

for timestamp in original_timestamps:
    signal_data = sensors[DEVICE_ID][timestamp]
    signal_voltage = [i * 3.6 / 4096.0 for i in signal_data['x']['waveform']]

    # Aplicar filtro passa-banda
    filtered_signal = bandpass_filter(signal_voltage, 15000, 38000, signal_data['odr'])

    # Extrair envelope
    envelope = extract_envelope(filtered_signal)

    signal_dbv = from_voltages_to_dbv(envelope)

    dbv_rms.append(rms_value(signal_dbv))
    dbv_peak.append(max(signal_dbv))
    crest_factors.append(max(signal_dbv) / rms_value(signal_dbv))
    kurtosis_values.append(kurtosis(signal_dbv))

# Definir o colormap personalizado
colors = [(0, 1, 0), (1, 1, 0), (1, 0, 0)]  # Verde -> Amarelo -> Vermelho
n_bins = [5]  # Número de bins para cada cor
cmap_name = 'my_list'
cm = mcolors.LinearSegmentedColormap.from_list(cmap_name, colors, N=sum(n_bins))

# Aumentar o tamanho dos gráficos
fig, axs = plt.subplots(2, 2, figsize=(18, 16))  # Tamanho aumentado para 18x16 polegadas

# Heatmap para dBV RMS
rms_heatmap = np.array(dbv_rms).reshape(1, -1)
im = axs[0, 0].imshow(rms_heatmap, cmap=cm, interpolation='nearest', aspect='auto')
axs[0, 0].set_title('dBV RMS')
axs[0, 0].set_xticks(range(len(original_timestamps)))
axs[0, 0].set_xticklabels(formatted_timestamps, rotation=45, ha='right')
fig.colorbar(im, ax=axs[0, 0])  # Adiciona barra de cores ao gráfico

# Heatmap para dBV Peak
peak_heatmap = np.array(dbv_peak).reshape(1, -1)
im = axs[0, 1].imshow(peak_heatmap, cmap=cm, interpolation='nearest', aspect='auto')
axs[0, 1].set_title('dBV Peak')
axs[0, 1].set_xticks(range(len(original_timestamps)))
axs[0, 1].set_xticklabels(formatted_timestamps, rotation=45, ha='right')
fig.colorbar(im, ax=axs[0, 1])

# Heatmap para Crest Factor
crest_factor_heatmap = np.array(crest_factors).reshape(1, -1)
im = axs[1, 0].imshow(crest_factor_heatmap, cmap=cm, interpolation='nearest', aspect='auto')
axs[1, 0].set_title('Crest Factor')
axs[1, 0].set_xticks(range(len(original_timestamps)))
axs[1, 0].set_xticklabels(formatted_timestamps, rotation=45, ha='right')
fig.colorbar(im, ax=axs[1, 0])

# Heatmap para Kurtosis
kurtosis_heatmap = np.array(kurtosis_values).reshape(1, -1)
im = axs[1, 1].imshow(kurtosis_heatmap, cmap=cm, interpolation='nearest', aspect='auto')
axs[1, 1].set_title('Kurtosis')
axs[1, 1].set_xticks(range(len(original_timestamps)))
axs[1, 1].set_xticklabels(formatted_timestamps, rotation=45, ha='right')
fig.colorbar(im, ax=axs[1, 1])

# Ajustar layout e exibir o gráfico
plt.tight_layout()
plt.show()

import numpy as np
import matplotlib.pyplot as plt
import matplotlib.colors as mcolors
import math
import datetime
from scipy.stats import kurtosis
from scipy.signal import butter, filtfilt, hilbert

# Constantes de configuração do microfone e nível de referência
TEST_CONDITION_SPL = 94.0  # dB SPL
MICROFONE_SENSITIVITY = -38  # dBV
VOLTAGE_REFERENCE_LEVEL = 10 ** (MICROFONE_SENSITIVITY / 20)
N_TIMESTAMPS = 30  # Número de timestamps
SIGNAL_LENGTH = 120  # Comprimento de cada sinal

# Função para converter voltagens em dBV
def from_voltages_to_dbv(signal):
    return [(20.0 * math.log10(abs(voltage) / VOLTAGE_REFERENCE_LEVEL) + MICROFONE_SENSITIVITY) + TEST_CONDITION_SPL for voltage in signal]

# Função para calcular o valor RMS
def rms_value(signal):
    return np.sqrt(np.mean(np.square(signal)))

# Função para aplicar filtro passa-banda
def bandpass_filter(data, lowcut, highcut, fs, order=5):
    nyq = 0.5 * fs  # Frequência de Nyquist
    low = lowcut / nyq
    high = highcut / nyq
    b, a = butter(order, [low, high], btype='band')
    y = filtfilt(b, a, data)
    return y

# Função para extrair o envelope do sinal
def extract_envelope(signal):
    analytic_signal = hilbert(signal)
    envelope = np.abs(analytic_signal)
    return envelope

# Simulação de dados com timestamps convertidos para datas
base_time = datetime.datetime(2023, 1, 1)  # Data base (início da época Unix)
sensors = {'DEVICE_ID': {'Timestamp {}'.format((base_time + datetime.timedelta(milliseconds=i)).strftime('%Y-%m-%d %H:%M:%S.%f')): {'odr': 25600, 'scale': 2, 'x': {'waveform': np.random.randint(0, 4096, SIGNAL_LENGTH)}} for i in range(N_TIMESTAMPS)}}
DEVICE_ID = 'DEVICE_ID'

# Extração dos timestamps originais e conversão para formato legível
original_timestamps = [timestamp for timestamp in sensors[DEVICE_ID].keys()]
formatted_timestamps = [datetime.datetime.strptime(timestamp.replace('Timestamp ', ''), '%Y-%m-%d %H:%M:%S.%f').strftime('%Y-%m-%d %H:%M:%S') for timestamp in original_timestamps]

# Preparar dados para heatmaps
dbv_rms = []
dbv_peak = []
crest_factors = []
kurtosis_values = []

for timestamp in original_timestamps:
    signal_data = sensors[DEVICE_ID][timestamp]
    signal_voltage = [i * 3.6 / 4096.0 for i in signal_data['x']['waveform']]

    # Aplicar filtro passa-banda com frequências normalizadas
    filtered_signal = bandpass_filter(signal_voltage, 15000, 38000, signal_data['odr'])

    # Extrair envelope
    envelope = extract_envelope(filtered_signal)

    signal_dbv = from_voltages_to_dbv(envelope)

    dbv_rms.append(rms_value(signal_dbv))
    dbv_peak.append(max(signal_dbv))
    crest_factors.append(max(signal_dbv) / rms_value(signal_dbv))
    kurtosis_values.append(kurtosis(signal_dbv))

# Definir o colormap personalizado
colors = [(0, 1, 0), (1, 1, 0), (1, 0, 0)]  # Verde -> Amarelo -> Vermelho
n_bins = [5]  # Número de bins para cada cor
cmap_name = 'my_list'
cm = mcolors.LinearSegmentedColormap.from_list(cmap_name, colors, N=sum(n_bins))

# Aumentar o tamanho dos gráficos
fig, axs = plt.subplots(2, 2, figsize=(18, 16))  # Tamanho aumentado para 18x16 polegadas

# Heatmap para dBV RMS
rms_heatmap = np.array(dbv_rms).reshape(1, -1)
im = axs[0, 0].imshow(rms_heatmap, cmap=cm, interpolation='nearest', aspect='auto')
axs[0, 0].set_title('dBV RMS')
axs[0, 0].set_xticks(range(len(original_timestamps)))
axs[0, 0].set_xticklabels(formatted_timestamps, rotation=45, ha='right')
fig.colorbar(im, ax=axs[0, 0])  # Adiciona barra de cores ao gráfico

# Heatmap para dBV Peak
peak_heatmap = np.array(dbv_peak).reshape(1, -1)
im = axs[0, 1].imshow(peak_heatmap, cmap=cm, interpolation='nearest', aspect='auto')
axs[0, 1].set_title('dBV Peak')
axs[0, 1].set_xticks(range(len(original_timestamps)))
axs[0, 1].set_xticklabels(formatted_timestamps, rotation=45, ha='right')
fig.colorbar(im, ax=axs[0, 1])

# Heatmap para Crest Factor
crest_factor_heatmap = np.array(crest_factors).reshape(1, -1)
im = axs[1, 0].imshow(crest_factor_heatmap, cmap=cm, interpolation='nearest', aspect='auto')
axs[1, 0].set_title('Crest Factor')
axs[1, 0].set_xticks(range(len(original_timestamps)))
axs[1, 0].set_xticklabels(formatted_timestamps, rotation=45, ha='right')
fig.colorbar(im, ax=axs[1, 0])

# Heatmap para Kurtosis
kurtosis_heatmap = np.array(kurtosis_values).reshape(1, -1)
im = axs[1, 1].imshow(kurtosis_heatmap, cmap=cm, interpolation='nearest', aspect='auto')
axs[1, 1].set_title('Kurtosis')
axs[1, 1].set_xticks(range(len(original_timestamps)))
axs[1, 1].set_xticklabels(formatted_timestamps, rotation=45, ha='right')
fig.colorbar(im, ax=axs[1, 1])

# Ajustar layout e exibir o gráfico
plt.tight_layout()
plt.show()

import numpy as np
import matplotlib.pyplot as plt
import matplotlib.colors as mcolors
import math
from scipy.fft import fft, ifft
import scipy.stats as stats
from sklearn.metrics import roc_curve, auc

# [Parte inicial do seu código original permanece inalterada]
# ...

# Funções adicionais para cálculo de parâmetros
def signal_energy(signal):
    return np.sum(np.square(signal))

def signal_variance(signal):
    return np.var(signal)

def signal_distortion(signal, noise):
    signal_power = np.mean(np.square(signal))
    noise_power = np.mean(np.square(noise))
    return 10 * np.log10(signal_power / noise_power) if noise_power != 0 else float('inf')

# [Parte de simulação de dados do seu código original permanece inalterada]
# ...

# Listas para armazenar os valores de Fator de Crista, Curtose e outros parâmetros
crest_factors = []
kurtosis_values = []
energy_values = []
variance_values = []
distortion_values = []

# Processamento de sinal para cada quadro de dados
timestamps = list(sensors[DEVICE_ID].keys())
for timestamp in timestamps:
    # [Código de processamento do sinal permanece inalterado]
    # ...

# [Código para plotar o heatmap e outros gráficos permanece inalterado]
# ...

# Simulação dos rótulos de classe baseada na energia do sinal
true_labels = [1 if energy > np.median(energy_values) else 0 for energy in energy_values]

# Calculando as taxas de Verdadeiros Positivos e Falsos Positivos para diferentes limiares
fpr, tpr, thresholds = roc_curve(true_labels, energy_values)

# Calculando a Área sob a Curva (AUC)
roc_auc = auc(fpr, tpr)

# Plotando a Curva ROC
plt.figure(figsize=(8, 6))
plt.plot(fpr, tpr, color='blue', lw=2, label='Curva ROC (área = %0.2f)' % roc_auc)
plt.plot([0, 1], [0, 1], color='gray', lw=2, linestyle='--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('Taxa de Falso Positivo')
plt.ylabel('Taxa de Verdadeiro Positivo')
plt.title('Curva ROC para Classificação de Sinal')
plt.legend(loc="lower right")
plt.show()

import numpy as np
import matplotlib.pyplot as plt
import matplotlib.colors as mcolors
import math
import datetime
from scipy.stats import kurtosis
from scipy.signal import butter, filtfilt, hilbert

# Constantes de configuração do microfone e nível de referência
TEST_CONDITION_SPL = 94.0  # dB SPL
MICROFONE_SENSITIVITY = -38  # dBV
VOLTAGE_REFERENCE_LEVEL = 10 ** (MICROFONE_SENSITIVITY / 20)
N_TIMESTAMPS = 30  # Número de timestamps
SIGNAL_LENGTH = 120  # Comprimento de cada sinal

# Função para converter voltagens em dBV
def from_voltages_to_dbv(signal):
    return [(20.0 * math.log10(abs(voltage) / VOLTAGE_REFERENCE_LEVEL) + MICROFONE_SENSITIVITY) + TEST_CONDITION_SPL for voltage in signal]

# Função para extrair o envelope do sinal
def extract_envelope(signal):
    analytic_signal = hilbert(signal)
    envelope = np.abs(analytic_signal)
    return envelope

# Simulação de dados com timestamps convertidos para datas
base_time = datetime.datetime(2023, 1, 1)  # Data base (início da época Unix)
sensors = {'DEVICE_ID': {'Timestamp {}'.format((base_time + datetime.timedelta(milliseconds=i)).strftime('%Y-%m-%d %H:%M:%S.%f')): {'odr': 25600, 'scale': 2, 'x': {'waveform': np.random.randint(0, 4096, SIGNAL_LENGTH)}} for i in range(N_TIMESTAMPS)}}
DEVICE_ID = 'DEVICE_ID'

# Extração dos timestamps originais e conversão para formato legível
original_timestamps = [timestamp for timestamp in sensors[DEVICE_ID].keys()]
formatted_timestamps = [datetime.datetime.strptime(timestamp.replace('Timestamp ', ''), '%Y-%m-%d %H:%M:%S.%f').strftime('%Y-%m-%d %H:%M:%S') for timestamp in original_timestamps]

# Preparar dados para heatmaps
dbv_rms = []
dbv_peak = []
crest_factors = []
kurtosis_values = []

# Armazenar os dados do sinal filtrado em uma matriz
filtered_signals = np.zeros((N_TIMESTAMPS, SIGNAL_LENGTH))
for i in range(N_TIMESTAMPS):
    signal_data = sensors[DEVICE_ID][original_timestamps[i]]
    signal_voltage = [i * 3.6 / 4096.0 for i in signal_data['x']['waveform']]

    # Aplicar filtro passa-banda
    filtered_signals[i] = bandpass_filter(signal_voltage, 15000, 38000, signal_data['odr'])

# Extrair o envelope do sinal e calcular as métricas desejadas
for i in range(N_TIMESTAMPS):
    signal_dbv = from_voltages_to_dbv(extract_envelope(filtered_signals[i]))

    dbv_rms.append(rms_value(signal_dbv))
    dbv_peak.append(max(signal_dbv))
    crest_factors.append(max(signal_dbv) / rms_value(signal_dbv))
    kurtosis_values.append(kurtosis(signal_dbv))

# Definir o colormap personalizado
colors = [(0, 1, 0), (1, 1, 0), (1, 0, 0)]  # Verde -> Amarelo -> Vermelho
n_bins = [5]  # Número de bins para cada cor
cmap_name = 'my_list'
cm = mcolors.LinearSegmentedColormap.from_list(cmap_name, colors, N=sum(n_bins))

# Aumentar o tamanho dos gráficos
fig, axs = plt.subplots(2, 2, figsize=(18, 16))  # Tamanho aumentado para 18x16 polegadas

# Heatmap para dBV RMS
rms_heatmap = np.array(dbv_rms).reshape(1, -1)
im = axs[0, 0].imshow(rms_heatmap, cmap=cm, interpolation='nearest', aspect='auto')
axs[0, 0].set_title('dBV RMS')
axs[0, 0].set_xticks(range(len(original_timestamps)))
axs[0, 0].set_xticklabels(formatted_timestamps, rotation=45, ha='right')
fig.colorbar(im, ax=axs[0, 0])  # Adiciona barra de cores ao gráfico

# Heatmap para dBV Peak
peak_heatmap = np.array(dbv_peak).reshape(1, -1)
im = axs[0, 1].imshow(peak_heatmap, cmap=cm, interpolation='nearest', aspect='auto')
axs[0, 1].set_title('dBV Peak')
axs[0, 1].set_xticks(range(len(original_timestamps)))
axs[0, 1].set_xticklabels(formatted_timestamps, rotation=45, ha='right')
fig.colorbar(im, ax=axs[0, 1])

# Heatmap para Crest Factor
crest_factor_heatmap = np.array(crest_factors).reshape(1, -1)
im = axs[1, 0].imshow(crest_factor_heatmap, cmap=cm, interpolation='nearest', aspect='auto')
axs[1, 0].set_title('Crest Factor')
axs[1, 0].set_xticks(range(len(original_timestamps)))
axs[1, 0].set_xticklabels(formatted_timestamps, rotation=45, ha='right')
fig.colorbar(im, ax=axs[1, 0])

# Heatmap para Kurtosis
kurtosis_heatmap = np.array(kurtosis_values).reshape(1, -1)
im = axs[1, 1].imshow(kurtosis_heatmap, cmap=cm, interpolation='nearest', aspect='auto')
axs[1, 1].set_title('Kurtosis')
axs[1, 1].set_xticks(range(len(original_timestamps)))
axs[1, 1].set_xticklabels(formatted_timestamps, rotation=45, ha='right')
fig.colorbar(im, ax=axs[1, 1])

# Ajustar layout e exibir o gráfico
plt.tight_layout()
plt.show()

import json
from datetime import datetime
from urllib.request import urlopen
import csv
from losantrest import Client

# Configurações para a consulta da API do Losant
ENVIRONMENT = "PRD"
START = 1693845121000
END = 1696609921000
DEVICE_ID = "64ecc6e384a8e6cb7d75eb0f"
TOKEN_DEV = 'eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJzdWIiOiI2MmMzNWE4NTM0ODcwNzBlM2IwMDAzZDAiLCJzdWJ0eXBlIjoiYXBpVG9rZW4iLCJzY29wZSI6WyJhbGwuQXBwbGljYXRpb24iXSwiaWF0IjoxNjU2OTY5ODYxLCJpc3MiOiJhcHAud25vbG9neS5pbyJ9.cLHE-GW1EKlaKpiprc_lfb2piK909_QglbXaOUGbWbI'
APPLICATION_ID_DEV = '5ef213f8caefb100074029ad'
TOKEN_PRD = 'eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJzdWIiOiI2MjgzZjM4MDk2NjBiMGNkZjY4MjJjMTQiLCJzdWJ0eXBlIjoiYXBpVG9rZW4iLCJzY29wZSI6WyJhbGwuQXBwbGljYXRpb24iXSwiaWF0IjoxNjUyODE0NzIwLCJpc3MiOiJhcHAud25vbG9neS5pbyJ9.t0CDFUKHevI1vI_TvPth018NxxjM8IpjHVlTkb_ouPo'
APPLICATION_ID_PRD = '5eed0126ec59a70008902b45'
if ENVIRONMENT == "PRD":
    TOKEN = TOKEN_PRD
    APPLICATION_ID = APPLICATION_ID_PRD
else:
    TOKEN = TOKEN_DEV
    APPLICATION_ID = APPLICATION_ID_DEV
query = {
    "aggregation": "NONE",
    "resolution": 0,
    "start": START,
    "end": END,
    "attributes": [
        "micWaveformX", "micWaveformY", "micWaveformZ",
        "vibWaveformX", "vibWaveformY", "vibWaveformZ",
        "magWaveformX", "magWaveformY", "magWaveformZ",
        "fftX", "fftY", "fftZ"
    ],
    "deviceIds": [DEVICE_ID]
}

losant_client = Client(auth_token=TOKEN, url="https://api.app.wnology.io")
result = losant_client.data.time_series_query(applicationId=APPLICATION_ID, query=query)

# Processamento dos dados
sampled_attributes = set(query["attributes"])
sensors = dict()

for device_id, device_value in result['devices'].items():
    for point in device_value['points']:
        timestamp = int(datetime.fromisoformat(point['time'][:-1]).timestamp() * 1000)
        for attribute_key, attribute_value in point['data'].items():
            if attribute_key in sampled_attributes:
                if device_id not in sensors:
                    sensors[device_id] = {}
                if timestamp not in sensors[device_id]:
                    sensors[device_id][timestamp] = {}
                axis = 'x' if 'X' in attribute_key else 'y' if 'Y' in attribute_key else 'z'
                if axis not in sensors[device_id][timestamp]:
                    sensors[device_id][timestamp][axis] = {}
                curve = 'waveform' if 'Waveform' in attribute_key else 'spectrum'
                f = urlopen(attribute_value)
                bulk_dict = json.load(f)
                f.close()
                if 'Waveform' in attribute_key:
                    sensors[device_id][timestamp][axis][curve] = bulk_dict
                elif 'fft' in attribute_key:
                    if curve not in sensors[device_id][timestamp][axis]:
                        sensors[device_id][timestamp][axis][curve] = {}
                    sensors[device_id][timestamp][axis][curve]['x'] = [float(d['f']) for d in bulk_dict]
                    sensors[device_id][timestamp][axis][curve]['y'] = [float(d['a']) for d in bulk_dict]

# Função para salvar os dados em CSV
def save_to_csv(sensors_data, filename):
    with open(filename, 'w', newline='') as file:
        writer = csv.writer(file)
        writer.writerow(['Device ID', 'Timestamp', 'Axis', 'Curve Type', 'Data'])
        for device_id, timestamps in sensors_data.items():
            for timestamp, axes in timestamps.items():
                for axis, curves in axes.items():
                    for curve, values in curves.items():
                        if isinstance(values, dict):
                            for x, y in zip(values['x'], values['y']):
                                writer.writerow([device_id, timestamp, axis, curve, f'{x},{y}'])
                        else:
                            writer.writerow([device_id, timestamp, axis, curve, ','.join(map(str, values))])

# Chamada da função para salvar os dados em CSV
save_to_csv(sensors, 'output.csv')